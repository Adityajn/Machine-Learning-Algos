{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = pandas.read_csv(url, names=names)\n",
    "array = dataframe.values\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(614, 8) (154, 8) (614,) (154,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,Y_train,Y_test  = train_test_split(X,Y,test_size=0.2,random_state=6)\n",
    "print(X_train.shape,X_test.shape,Y_train.shape,Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.811688311688\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=1, min_child_weight=1, missing=None, n_estimators=300,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "tuned_parameters = [{'n_estimators': [100,300,500,1000],\n",
    "                     'max_depth': [1],\n",
    "                     'learning_rate':[0.01,0.05,0.1]\n",
    "                    }]\n",
    "model = XGBClassifier()\n",
    "gridsearch = GridSearchCV(model,tuned_parameters)\n",
    "gridsearch.fit(X_train,Y_train)\n",
    "print(gridsearch.score(X_test,Y_test))\n",
    "gridsearch.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.824675324675\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "        learning_rate=0.05, max_depth=3, min_child_samples=20,\n",
       "        min_child_weight=0.001, min_split_gain=0.0, n_estimators=100,\n",
       "        n_jobs=-1, num_leaves=31, objective='binary', random_state=None,\n",
       "        reg_alpha=0.0, reg_lambda=0.0, silent=False, subsample=1.0,\n",
       "        subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "tuned_parameters = [{'n_estimators':[50,100,200],\n",
    "                    'max_depth':[3,10,15,-1],\n",
    "                    'learning_rate':[0.05],\n",
    "                    'num_leaves':[31],\n",
    "                     'boosting_type':['gbdt']\n",
    "                    }]\n",
    "model  = LGBMClassifier(objective='binary',n_jobs=-1,silent=False)\n",
    "gridsearch = GridSearchCV(model,tuned_parameters)\n",
    "gridsearch.fit(X_train,Y_train)\n",
    "print(gridsearch.score(X_test,Y_test))\n",
    "gridsearch.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6790971\ttotal: 69.5ms\tremaining: 1m 9s\n",
      "1:\tlearn: 0.6662996\ttotal: 79.4ms\tremaining: 39.6s\n",
      "2:\tlearn: 0.6560410\ttotal: 88.8ms\tremaining: 29.5s\n",
      "3:\tlearn: 0.6437958\ttotal: 97.9ms\tremaining: 24.4s\n",
      "4:\tlearn: 0.6311869\ttotal: 107ms\tremaining: 21.3s\n",
      "5:\tlearn: 0.6201830\ttotal: 116ms\tremaining: 19.2s\n",
      "6:\tlearn: 0.6101677\ttotal: 125ms\tremaining: 17.8s\n",
      "7:\tlearn: 0.6008485\ttotal: 135ms\tremaining: 16.7s\n",
      "8:\tlearn: 0.5897170\ttotal: 145ms\tremaining: 15.9s\n",
      "9:\tlearn: 0.5806199\ttotal: 153ms\tremaining: 15.2s\n",
      "10:\tlearn: 0.5744672\ttotal: 163ms\tremaining: 14.6s\n",
      "11:\tlearn: 0.5673245\ttotal: 172ms\tremaining: 14.1s\n",
      "12:\tlearn: 0.5589828\ttotal: 183ms\tremaining: 13.9s\n",
      "13:\tlearn: 0.5509198\ttotal: 191ms\tremaining: 13.5s\n",
      "14:\tlearn: 0.5454464\ttotal: 197ms\tremaining: 13s\n",
      "15:\tlearn: 0.5388876\ttotal: 207ms\tremaining: 12.7s\n",
      "16:\tlearn: 0.5341679\ttotal: 214ms\tremaining: 12.4s\n",
      "17:\tlearn: 0.5274935\ttotal: 221ms\tremaining: 12s\n",
      "18:\tlearn: 0.5223714\ttotal: 230ms\tremaining: 11.9s\n",
      "19:\tlearn: 0.5163025\ttotal: 240ms\tremaining: 11.8s\n",
      "20:\tlearn: 0.5116911\ttotal: 249ms\tremaining: 11.6s\n",
      "21:\tlearn: 0.5077015\ttotal: 258ms\tremaining: 11.4s\n",
      "22:\tlearn: 0.5025838\ttotal: 264ms\tremaining: 11.2s\n",
      "23:\tlearn: 0.4993221\ttotal: 277ms\tremaining: 11.3s\n",
      "24:\tlearn: 0.4952028\ttotal: 297ms\tremaining: 11.6s\n",
      "25:\tlearn: 0.4923619\ttotal: 309ms\tremaining: 11.6s\n",
      "26:\tlearn: 0.4881168\ttotal: 319ms\tremaining: 11.5s\n",
      "27:\tlearn: 0.4852759\ttotal: 328ms\tremaining: 11.4s\n",
      "28:\tlearn: 0.4812382\ttotal: 337ms\tremaining: 11.3s\n",
      "29:\tlearn: 0.4776386\ttotal: 344ms\tremaining: 11.1s\n",
      "30:\tlearn: 0.4748479\ttotal: 350ms\tremaining: 10.9s\n",
      "31:\tlearn: 0.4726503\ttotal: 355ms\tremaining: 10.7s\n",
      "32:\tlearn: 0.4688554\ttotal: 361ms\tremaining: 10.6s\n",
      "33:\tlearn: 0.4651817\ttotal: 367ms\tremaining: 10.4s\n",
      "34:\tlearn: 0.4617612\ttotal: 373ms\tremaining: 10.3s\n",
      "35:\tlearn: 0.4591154\ttotal: 380ms\tremaining: 10.2s\n",
      "36:\tlearn: 0.4561329\ttotal: 386ms\tremaining: 10.1s\n",
      "37:\tlearn: 0.4531503\ttotal: 393ms\tremaining: 9.94s\n",
      "38:\tlearn: 0.4514468\ttotal: 399ms\tremaining: 9.83s\n",
      "39:\tlearn: 0.4491618\ttotal: 405ms\tremaining: 9.72s\n",
      "40:\tlearn: 0.4473493\ttotal: 411ms\tremaining: 9.62s\n",
      "41:\tlearn: 0.4445136\ttotal: 418ms\tremaining: 9.53s\n",
      "42:\tlearn: 0.4431407\ttotal: 427ms\tremaining: 9.49s\n",
      "43:\tlearn: 0.4405159\ttotal: 435ms\tremaining: 9.45s\n",
      "44:\tlearn: 0.4383629\ttotal: 442ms\tremaining: 9.37s\n",
      "45:\tlearn: 0.4372085\ttotal: 446ms\tremaining: 9.25s\n",
      "46:\tlearn: 0.4348171\ttotal: 453ms\tremaining: 9.18s\n",
      "47:\tlearn: 0.4328342\ttotal: 459ms\tremaining: 9.11s\n",
      "48:\tlearn: 0.4312924\ttotal: 466ms\tremaining: 9.04s\n",
      "49:\tlearn: 0.4294619\ttotal: 473ms\tremaining: 8.99s\n",
      "50:\tlearn: 0.4279224\ttotal: 489ms\tremaining: 9.1s\n",
      "51:\tlearn: 0.4261732\ttotal: 505ms\tremaining: 9.2s\n",
      "52:\tlearn: 0.4248542\ttotal: 513ms\tremaining: 9.17s\n",
      "53:\tlearn: 0.4233924\ttotal: 521ms\tremaining: 9.13s\n",
      "54:\tlearn: 0.4220345\ttotal: 530ms\tremaining: 9.1s\n",
      "55:\tlearn: 0.4207998\ttotal: 536ms\tremaining: 9.04s\n",
      "56:\tlearn: 0.4186434\ttotal: 543ms\tremaining: 8.98s\n",
      "57:\tlearn: 0.4171695\ttotal: 549ms\tremaining: 8.91s\n",
      "58:\tlearn: 0.4157051\ttotal: 555ms\tremaining: 8.86s\n",
      "59:\tlearn: 0.4135789\ttotal: 562ms\tremaining: 8.81s\n",
      "60:\tlearn: 0.4125488\ttotal: 569ms\tremaining: 8.76s\n",
      "61:\tlearn: 0.4116063\ttotal: 575ms\tremaining: 8.7s\n",
      "62:\tlearn: 0.4100860\ttotal: 581ms\tremaining: 8.65s\n",
      "63:\tlearn: 0.4084676\ttotal: 587ms\tremaining: 8.59s\n",
      "64:\tlearn: 0.4073131\ttotal: 593ms\tremaining: 8.54s\n",
      "65:\tlearn: 0.4056151\ttotal: 600ms\tremaining: 8.49s\n",
      "66:\tlearn: 0.4043727\ttotal: 606ms\tremaining: 8.43s\n",
      "67:\tlearn: 0.4026155\ttotal: 612ms\tremaining: 8.39s\n",
      "68:\tlearn: 0.4006230\ttotal: 619ms\tremaining: 8.35s\n",
      "69:\tlearn: 0.3996089\ttotal: 626ms\tremaining: 8.31s\n",
      "70:\tlearn: 0.3984594\ttotal: 632ms\tremaining: 8.27s\n",
      "71:\tlearn: 0.3969261\ttotal: 638ms\tremaining: 8.22s\n",
      "72:\tlearn: 0.3961014\ttotal: 644ms\tremaining: 8.18s\n",
      "73:\tlearn: 0.3952893\ttotal: 650ms\tremaining: 8.14s\n",
      "74:\tlearn: 0.3941860\ttotal: 657ms\tremaining: 8.1s\n",
      "75:\tlearn: 0.3929318\ttotal: 663ms\tremaining: 8.07s\n",
      "76:\tlearn: 0.3918266\ttotal: 671ms\tremaining: 8.04s\n",
      "77:\tlearn: 0.3902140\ttotal: 689ms\tremaining: 8.15s\n",
      "78:\tlearn: 0.3889112\ttotal: 701ms\tremaining: 8.17s\n",
      "79:\tlearn: 0.3883418\ttotal: 711ms\tremaining: 8.18s\n",
      "80:\tlearn: 0.3873081\ttotal: 718ms\tremaining: 8.15s\n",
      "81:\tlearn: 0.3853401\ttotal: 727ms\tremaining: 8.14s\n",
      "82:\tlearn: 0.3847131\ttotal: 734ms\tremaining: 8.1s\n",
      "83:\tlearn: 0.3836683\ttotal: 740ms\tremaining: 8.07s\n",
      "84:\tlearn: 0.3817502\ttotal: 746ms\tremaining: 8.03s\n",
      "85:\tlearn: 0.3808573\ttotal: 752ms\tremaining: 8s\n",
      "86:\tlearn: 0.3798627\ttotal: 759ms\tremaining: 7.96s\n",
      "87:\tlearn: 0.3782448\ttotal: 765ms\tremaining: 7.93s\n",
      "88:\tlearn: 0.3774308\ttotal: 772ms\tremaining: 7.9s\n",
      "89:\tlearn: 0.3764509\ttotal: 778ms\tremaining: 7.86s\n",
      "90:\tlearn: 0.3755750\ttotal: 784ms\tremaining: 7.83s\n",
      "91:\tlearn: 0.3741867\ttotal: 790ms\tremaining: 7.8s\n",
      "92:\tlearn: 0.3726782\ttotal: 797ms\tremaining: 7.77s\n",
      "93:\tlearn: 0.3713958\ttotal: 804ms\tremaining: 7.75s\n",
      "94:\tlearn: 0.3707894\ttotal: 810ms\tremaining: 7.72s\n",
      "95:\tlearn: 0.3697694\ttotal: 816ms\tremaining: 7.68s\n",
      "96:\tlearn: 0.3686867\ttotal: 823ms\tremaining: 7.66s\n",
      "97:\tlearn: 0.3662654\ttotal: 829ms\tremaining: 7.63s\n",
      "98:\tlearn: 0.3658144\ttotal: 836ms\tremaining: 7.61s\n",
      "99:\tlearn: 0.3650470\ttotal: 847ms\tremaining: 7.62s\n",
      "100:\tlearn: 0.3636151\ttotal: 854ms\tremaining: 7.6s\n",
      "101:\tlearn: 0.3628258\ttotal: 860ms\tremaining: 7.57s\n",
      "102:\tlearn: 0.3615772\ttotal: 868ms\tremaining: 7.56s\n",
      "103:\tlearn: 0.3606814\ttotal: 886ms\tremaining: 7.64s\n",
      "104:\tlearn: 0.3598366\ttotal: 903ms\tremaining: 7.69s\n",
      "105:\tlearn: 0.3589874\ttotal: 910ms\tremaining: 7.67s\n",
      "106:\tlearn: 0.3583694\ttotal: 920ms\tremaining: 7.68s\n",
      "107:\tlearn: 0.3575913\ttotal: 926ms\tremaining: 7.65s\n",
      "108:\tlearn: 0.3563097\ttotal: 933ms\tremaining: 7.63s\n",
      "109:\tlearn: 0.3557866\ttotal: 940ms\tremaining: 7.6s\n",
      "110:\tlearn: 0.3545518\ttotal: 946ms\tremaining: 7.58s\n",
      "111:\tlearn: 0.3530216\ttotal: 952ms\tremaining: 7.55s\n",
      "112:\tlearn: 0.3523509\ttotal: 958ms\tremaining: 7.52s\n",
      "113:\tlearn: 0.3518150\ttotal: 965ms\tremaining: 7.5s\n",
      "114:\tlearn: 0.3509003\ttotal: 971ms\tremaining: 7.48s\n",
      "115:\tlearn: 0.3502699\ttotal: 978ms\tremaining: 7.45s\n",
      "116:\tlearn: 0.3495521\ttotal: 984ms\tremaining: 7.43s\n",
      "117:\tlearn: 0.3488746\ttotal: 991ms\tremaining: 7.4s\n",
      "118:\tlearn: 0.3483212\ttotal: 998ms\tremaining: 7.38s\n",
      "119:\tlearn: 0.3475802\ttotal: 1s\tremaining: 7.36s\n",
      "120:\tlearn: 0.3470554\ttotal: 1.01s\tremaining: 7.34s\n",
      "121:\tlearn: 0.3463322\ttotal: 1.02s\tremaining: 7.31s\n",
      "122:\tlearn: 0.3457537\ttotal: 1.02s\tremaining: 7.29s\n",
      "123:\tlearn: 0.3452302\ttotal: 1.03s\tremaining: 7.27s\n",
      "124:\tlearn: 0.3439122\ttotal: 1.04s\tremaining: 7.25s\n",
      "125:\tlearn: 0.3431405\ttotal: 1.04s\tremaining: 7.23s\n",
      "126:\tlearn: 0.3421773\ttotal: 1.05s\tremaining: 7.21s\n",
      "127:\tlearn: 0.3413787\ttotal: 1.05s\tremaining: 7.19s\n",
      "128:\tlearn: 0.3403724\ttotal: 1.06s\tremaining: 7.17s\n",
      "129:\tlearn: 0.3397113\ttotal: 1.07s\tremaining: 7.17s\n",
      "130:\tlearn: 0.3391056\ttotal: 1.08s\tremaining: 7.17s\n",
      "131:\tlearn: 0.3389345\ttotal: 1.09s\tremaining: 7.15s\n",
      "132:\tlearn: 0.3375367\ttotal: 1.1s\tremaining: 7.18s\n",
      "133:\tlearn: 0.3366702\ttotal: 1.11s\tremaining: 7.19s\n",
      "134:\tlearn: 0.3355724\ttotal: 1.12s\tremaining: 7.19s\n",
      "135:\tlearn: 0.3351266\ttotal: 1.15s\tremaining: 7.31s\n",
      "136:\tlearn: 0.3341805\ttotal: 1.16s\tremaining: 7.3s\n",
      "137:\tlearn: 0.3334007\ttotal: 1.17s\tremaining: 7.3s\n",
      "138:\tlearn: 0.3325549\ttotal: 1.17s\tremaining: 7.28s\n",
      "139:\tlearn: 0.3317234\ttotal: 1.18s\tremaining: 7.26s\n",
      "140:\tlearn: 0.3307199\ttotal: 1.19s\tremaining: 7.24s\n",
      "141:\tlearn: 0.3300475\ttotal: 1.19s\tremaining: 7.21s\n",
      "142:\tlearn: 0.3294813\ttotal: 1.2s\tremaining: 7.19s\n",
      "143:\tlearn: 0.3289471\ttotal: 1.21s\tremaining: 7.19s\n",
      "144:\tlearn: 0.3286517\ttotal: 1.22s\tremaining: 7.17s\n",
      "145:\tlearn: 0.3281798\ttotal: 1.22s\tremaining: 7.15s\n",
      "146:\tlearn: 0.3273618\ttotal: 1.23s\tremaining: 7.13s\n",
      "147:\tlearn: 0.3265208\ttotal: 1.24s\tremaining: 7.12s\n",
      "148:\tlearn: 0.3250325\ttotal: 1.24s\tremaining: 7.1s\n",
      "149:\tlearn: 0.3245162\ttotal: 1.25s\tremaining: 7.09s\n",
      "150:\tlearn: 0.3232294\ttotal: 1.26s\tremaining: 7.07s\n",
      "151:\tlearn: 0.3225146\ttotal: 1.26s\tremaining: 7.05s\n",
      "152:\tlearn: 0.3214799\ttotal: 1.28s\tremaining: 7.08s\n",
      "153:\tlearn: 0.3206139\ttotal: 1.29s\tremaining: 7.08s\n",
      "154:\tlearn: 0.3194732\ttotal: 1.3s\tremaining: 7.11s\n",
      "155:\tlearn: 0.3185858\ttotal: 1.32s\tremaining: 7.15s\n",
      "156:\tlearn: 0.3179382\ttotal: 1.33s\tremaining: 7.16s\n",
      "157:\tlearn: 0.3174462\ttotal: 1.34s\tremaining: 7.16s\n",
      "158:\tlearn: 0.3170234\ttotal: 1.35s\tremaining: 7.15s\n",
      "159:\tlearn: 0.3159174\ttotal: 1.36s\tremaining: 7.16s\n",
      "160:\tlearn: 0.3140651\ttotal: 1.37s\tremaining: 7.15s\n",
      "161:\tlearn: 0.3137787\ttotal: 1.38s\tremaining: 7.16s\n",
      "162:\tlearn: 0.3133030\ttotal: 1.39s\tremaining: 7.16s\n",
      "163:\tlearn: 0.3128718\ttotal: 1.4s\tremaining: 7.15s\n",
      "164:\tlearn: 0.3121500\ttotal: 1.41s\tremaining: 7.14s\n",
      "165:\tlearn: 0.3119992\ttotal: 1.42s\tremaining: 7.13s\n",
      "166:\tlearn: 0.3118399\ttotal: 1.43s\tremaining: 7.11s\n",
      "167:\tlearn: 0.3109867\ttotal: 1.43s\tremaining: 7.1s\n",
      "168:\tlearn: 0.3104598\ttotal: 1.44s\tremaining: 7.09s\n",
      "169:\tlearn: 0.3101347\ttotal: 1.45s\tremaining: 7.09s\n",
      "170:\tlearn: 0.3096118\ttotal: 1.46s\tremaining: 7.08s\n",
      "171:\tlearn: 0.3088503\ttotal: 1.47s\tremaining: 7.07s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172:\tlearn: 0.3084755\ttotal: 1.48s\tremaining: 7.06s\n",
      "173:\tlearn: 0.3078986\ttotal: 1.49s\tremaining: 7.07s\n",
      "174:\tlearn: 0.3073706\ttotal: 1.5s\tremaining: 7.06s\n",
      "175:\tlearn: 0.3069123\ttotal: 1.51s\tremaining: 7.06s\n",
      "176:\tlearn: 0.3066056\ttotal: 1.53s\tremaining: 7.11s\n",
      "177:\tlearn: 0.3063201\ttotal: 1.54s\tremaining: 7.1s\n",
      "178:\tlearn: 0.3056130\ttotal: 1.55s\tremaining: 7.1s\n",
      "179:\tlearn: 0.3052777\ttotal: 1.56s\tremaining: 7.09s\n",
      "180:\tlearn: 0.3045605\ttotal: 1.56s\tremaining: 7.08s\n",
      "181:\tlearn: 0.3033887\ttotal: 1.57s\tremaining: 7.06s\n",
      "182:\tlearn: 0.3023964\ttotal: 1.58s\tremaining: 7.05s\n",
      "183:\tlearn: 0.3020972\ttotal: 1.59s\tremaining: 7.03s\n",
      "184:\tlearn: 0.3012015\ttotal: 1.59s\tremaining: 7.02s\n",
      "185:\tlearn: 0.3004606\ttotal: 1.6s\tremaining: 7s\n",
      "186:\tlearn: 0.3002063\ttotal: 1.61s\tremaining: 6.98s\n",
      "187:\tlearn: 0.2996952\ttotal: 1.61s\tremaining: 6.97s\n",
      "188:\tlearn: 0.2988946\ttotal: 1.62s\tremaining: 6.95s\n",
      "189:\tlearn: 0.2981282\ttotal: 1.63s\tremaining: 6.94s\n",
      "190:\tlearn: 0.2976746\ttotal: 1.63s\tremaining: 6.92s\n",
      "191:\tlearn: 0.2971917\ttotal: 1.64s\tremaining: 6.91s\n",
      "192:\tlearn: 0.2967287\ttotal: 1.65s\tremaining: 6.89s\n",
      "193:\tlearn: 0.2961316\ttotal: 1.66s\tremaining: 6.88s\n",
      "194:\tlearn: 0.2955329\ttotal: 1.66s\tremaining: 6.87s\n",
      "195:\tlearn: 0.2945178\ttotal: 1.67s\tremaining: 6.86s\n",
      "196:\tlearn: 0.2927277\ttotal: 1.68s\tremaining: 6.86s\n",
      "197:\tlearn: 0.2922380\ttotal: 1.69s\tremaining: 6.85s\n",
      "198:\tlearn: 0.2911647\ttotal: 1.71s\tremaining: 6.86s\n",
      "199:\tlearn: 0.2905739\ttotal: 1.71s\tremaining: 6.84s\n",
      "200:\tlearn: 0.2897843\ttotal: 1.72s\tremaining: 6.83s\n",
      "201:\tlearn: 0.2885796\ttotal: 1.73s\tremaining: 6.82s\n",
      "202:\tlearn: 0.2879985\ttotal: 1.73s\tremaining: 6.81s\n",
      "203:\tlearn: 0.2872672\ttotal: 1.74s\tremaining: 6.79s\n",
      "204:\tlearn: 0.2865534\ttotal: 1.75s\tremaining: 6.77s\n",
      "205:\tlearn: 0.2859952\ttotal: 1.75s\tremaining: 6.75s\n",
      "206:\tlearn: 0.2855705\ttotal: 1.76s\tremaining: 6.74s\n",
      "207:\tlearn: 0.2850981\ttotal: 1.77s\tremaining: 6.72s\n",
      "208:\tlearn: 0.2847133\ttotal: 1.78s\tremaining: 6.73s\n",
      "209:\tlearn: 0.2842812\ttotal: 1.79s\tremaining: 6.73s\n",
      "210:\tlearn: 0.2836697\ttotal: 1.79s\tremaining: 6.71s\n",
      "211:\tlearn: 0.2827265\ttotal: 1.8s\tremaining: 6.7s\n",
      "212:\tlearn: 0.2816497\ttotal: 1.81s\tremaining: 6.68s\n",
      "213:\tlearn: 0.2812505\ttotal: 1.82s\tremaining: 6.69s\n",
      "214:\tlearn: 0.2807757\ttotal: 1.83s\tremaining: 6.68s\n",
      "215:\tlearn: 0.2803278\ttotal: 1.84s\tremaining: 6.67s\n",
      "216:\tlearn: 0.2791986\ttotal: 1.84s\tremaining: 6.65s\n",
      "217:\tlearn: 0.2786723\ttotal: 1.85s\tremaining: 6.64s\n",
      "218:\tlearn: 0.2782658\ttotal: 1.86s\tremaining: 6.62s\n",
      "219:\tlearn: 0.2775609\ttotal: 1.86s\tremaining: 6.61s\n",
      "220:\tlearn: 0.2771079\ttotal: 1.87s\tremaining: 6.59s\n",
      "221:\tlearn: 0.2765732\ttotal: 1.88s\tremaining: 6.57s\n",
      "222:\tlearn: 0.2759988\ttotal: 1.89s\tremaining: 6.58s\n",
      "223:\tlearn: 0.2756062\ttotal: 1.9s\tremaining: 6.57s\n",
      "224:\tlearn: 0.2749163\ttotal: 1.91s\tremaining: 6.57s\n",
      "225:\tlearn: 0.2745860\ttotal: 1.91s\tremaining: 6.55s\n",
      "226:\tlearn: 0.2741994\ttotal: 1.92s\tremaining: 6.55s\n",
      "227:\tlearn: 0.2731782\ttotal: 1.93s\tremaining: 6.53s\n",
      "228:\tlearn: 0.2723843\ttotal: 1.94s\tremaining: 6.52s\n",
      "229:\tlearn: 0.2719356\ttotal: 1.94s\tremaining: 6.5s\n",
      "230:\tlearn: 0.2712136\ttotal: 1.95s\tremaining: 6.49s\n",
      "231:\tlearn: 0.2706124\ttotal: 1.96s\tremaining: 6.47s\n",
      "232:\tlearn: 0.2696289\ttotal: 1.96s\tremaining: 6.46s\n",
      "233:\tlearn: 0.2687636\ttotal: 1.97s\tremaining: 6.44s\n",
      "234:\tlearn: 0.2682747\ttotal: 1.97s\tremaining: 6.43s\n",
      "235:\tlearn: 0.2676422\ttotal: 1.98s\tremaining: 6.41s\n",
      "236:\tlearn: 0.2671292\ttotal: 1.99s\tremaining: 6.39s\n",
      "237:\tlearn: 0.2662387\ttotal: 1.99s\tremaining: 6.38s\n",
      "238:\tlearn: 0.2658969\ttotal: 2s\tremaining: 6.37s\n",
      "239:\tlearn: 0.2653245\ttotal: 2s\tremaining: 6.35s\n",
      "240:\tlearn: 0.2643425\ttotal: 2.01s\tremaining: 6.34s\n",
      "241:\tlearn: 0.2635093\ttotal: 2.02s\tremaining: 6.32s\n",
      "242:\tlearn: 0.2623245\ttotal: 2.02s\tremaining: 6.31s\n",
      "243:\tlearn: 0.2617779\ttotal: 2.03s\tremaining: 6.29s\n",
      "244:\tlearn: 0.2612062\ttotal: 2.04s\tremaining: 6.28s\n",
      "245:\tlearn: 0.2605840\ttotal: 2.04s\tremaining: 6.26s\n",
      "246:\tlearn: 0.2603556\ttotal: 2.05s\tremaining: 6.25s\n",
      "247:\tlearn: 0.2600076\ttotal: 2.06s\tremaining: 6.24s\n",
      "248:\tlearn: 0.2598165\ttotal: 2.06s\tremaining: 6.22s\n",
      "249:\tlearn: 0.2594982\ttotal: 2.07s\tremaining: 6.21s\n",
      "250:\tlearn: 0.2588419\ttotal: 2.08s\tremaining: 6.2s\n",
      "251:\tlearn: 0.2585512\ttotal: 2.09s\tremaining: 6.19s\n",
      "252:\tlearn: 0.2580533\ttotal: 2.1s\tremaining: 6.19s\n",
      "253:\tlearn: 0.2577368\ttotal: 2.11s\tremaining: 6.2s\n",
      "254:\tlearn: 0.2568758\ttotal: 2.12s\tremaining: 6.19s\n",
      "255:\tlearn: 0.2566534\ttotal: 2.12s\tremaining: 6.17s\n",
      "256:\tlearn: 0.2561042\ttotal: 2.14s\tremaining: 6.18s\n",
      "257:\tlearn: 0.2556904\ttotal: 2.14s\tremaining: 6.16s\n",
      "258:\tlearn: 0.2546089\ttotal: 2.15s\tremaining: 6.15s\n",
      "259:\tlearn: 0.2536993\ttotal: 2.16s\tremaining: 6.14s\n",
      "260:\tlearn: 0.2534932\ttotal: 2.16s\tremaining: 6.12s\n",
      "261:\tlearn: 0.2523389\ttotal: 2.17s\tremaining: 6.11s\n",
      "262:\tlearn: 0.2514995\ttotal: 2.18s\tremaining: 6.1s\n",
      "263:\tlearn: 0.2509321\ttotal: 2.19s\tremaining: 6.1s\n",
      "264:\tlearn: 0.2505019\ttotal: 2.2s\tremaining: 6.09s\n",
      "265:\tlearn: 0.2493692\ttotal: 2.21s\tremaining: 6.09s\n",
      "266:\tlearn: 0.2484098\ttotal: 2.23s\tremaining: 6.12s\n",
      "267:\tlearn: 0.2480422\ttotal: 2.24s\tremaining: 6.13s\n",
      "268:\tlearn: 0.2474192\ttotal: 2.27s\tremaining: 6.17s\n",
      "269:\tlearn: 0.2467155\ttotal: 2.29s\tremaining: 6.2s\n",
      "270:\tlearn: 0.2461052\ttotal: 2.31s\tremaining: 6.21s\n",
      "271:\tlearn: 0.2457351\ttotal: 2.32s\tremaining: 6.21s\n",
      "272:\tlearn: 0.2452287\ttotal: 2.33s\tremaining: 6.22s\n",
      "273:\tlearn: 0.2440287\ttotal: 2.35s\tremaining: 6.24s\n",
      "274:\tlearn: 0.2432075\ttotal: 2.37s\tremaining: 6.24s\n",
      "275:\tlearn: 0.2426873\ttotal: 2.38s\tremaining: 6.25s\n",
      "276:\tlearn: 0.2419016\ttotal: 2.4s\tremaining: 6.28s\n",
      "277:\tlearn: 0.2411655\ttotal: 2.42s\tremaining: 6.29s\n",
      "278:\tlearn: 0.2407576\ttotal: 2.45s\tremaining: 6.33s\n",
      "279:\tlearn: 0.2401133\ttotal: 2.46s\tremaining: 6.33s\n",
      "280:\tlearn: 0.2393430\ttotal: 2.47s\tremaining: 6.32s\n",
      "281:\tlearn: 0.2387543\ttotal: 2.48s\tremaining: 6.32s\n",
      "282:\tlearn: 0.2382355\ttotal: 2.49s\tremaining: 6.3s\n",
      "283:\tlearn: 0.2376924\ttotal: 2.5s\tremaining: 6.31s\n",
      "284:\tlearn: 0.2368114\ttotal: 2.52s\tremaining: 6.33s\n",
      "285:\tlearn: 0.2362882\ttotal: 2.54s\tremaining: 6.34s\n",
      "286:\tlearn: 0.2355666\ttotal: 2.56s\tremaining: 6.35s\n",
      "287:\tlearn: 0.2347133\ttotal: 2.58s\tremaining: 6.37s\n",
      "288:\tlearn: 0.2345260\ttotal: 2.59s\tremaining: 6.37s\n",
      "289:\tlearn: 0.2339870\ttotal: 2.61s\tremaining: 6.38s\n",
      "290:\tlearn: 0.2333759\ttotal: 2.63s\tremaining: 6.4s\n",
      "291:\tlearn: 0.2331265\ttotal: 2.65s\tremaining: 6.42s\n",
      "292:\tlearn: 0.2323655\ttotal: 2.66s\tremaining: 6.42s\n",
      "293:\tlearn: 0.2316094\ttotal: 2.69s\tremaining: 6.47s\n",
      "294:\tlearn: 0.2310256\ttotal: 2.72s\tremaining: 6.5s\n",
      "295:\tlearn: 0.2305364\ttotal: 2.74s\tremaining: 6.52s\n",
      "296:\tlearn: 0.2298903\ttotal: 2.77s\tremaining: 6.54s\n",
      "297:\tlearn: 0.2294302\ttotal: 2.79s\tremaining: 6.57s\n",
      "298:\tlearn: 0.2291422\ttotal: 2.81s\tremaining: 6.59s\n",
      "299:\tlearn: 0.2287345\ttotal: 2.82s\tremaining: 6.59s\n",
      "300:\tlearn: 0.2285667\ttotal: 2.85s\tremaining: 6.63s\n",
      "301:\tlearn: 0.2280941\ttotal: 2.88s\tremaining: 6.66s\n",
      "302:\tlearn: 0.2276329\ttotal: 2.91s\tremaining: 6.7s\n",
      "303:\tlearn: 0.2271036\ttotal: 2.93s\tremaining: 6.71s\n",
      "304:\tlearn: 0.2263396\ttotal: 2.95s\tremaining: 6.72s\n",
      "305:\tlearn: 0.2260055\ttotal: 2.97s\tremaining: 6.73s\n",
      "306:\tlearn: 0.2251211\ttotal: 2.99s\tremaining: 6.75s\n",
      "307:\tlearn: 0.2244826\ttotal: 3s\tremaining: 6.74s\n",
      "308:\tlearn: 0.2240013\ttotal: 3.01s\tremaining: 6.72s\n",
      "309:\tlearn: 0.2233174\ttotal: 3.01s\tremaining: 6.71s\n",
      "310:\tlearn: 0.2228917\ttotal: 3.02s\tremaining: 6.7s\n",
      "311:\tlearn: 0.2226323\ttotal: 3.03s\tremaining: 6.68s\n",
      "312:\tlearn: 0.2222563\ttotal: 3.04s\tremaining: 6.67s\n",
      "313:\tlearn: 0.2220104\ttotal: 3.04s\tremaining: 6.65s\n",
      "314:\tlearn: 0.2214321\ttotal: 3.05s\tremaining: 6.64s\n",
      "315:\tlearn: 0.2210432\ttotal: 3.06s\tremaining: 6.63s\n",
      "316:\tlearn: 0.2207089\ttotal: 3.08s\tremaining: 6.64s\n",
      "317:\tlearn: 0.2204999\ttotal: 3.09s\tremaining: 6.64s\n",
      "318:\tlearn: 0.2201287\ttotal: 3.12s\tremaining: 6.65s\n",
      "319:\tlearn: 0.2196149\ttotal: 3.14s\tremaining: 6.68s\n",
      "320:\tlearn: 0.2191502\ttotal: 3.17s\tremaining: 6.71s\n",
      "321:\tlearn: 0.2185062\ttotal: 3.19s\tremaining: 6.72s\n",
      "322:\tlearn: 0.2180738\ttotal: 3.21s\tremaining: 6.73s\n",
      "323:\tlearn: 0.2172762\ttotal: 3.24s\tremaining: 6.76s\n",
      "324:\tlearn: 0.2165815\ttotal: 3.26s\tremaining: 6.77s\n",
      "325:\tlearn: 0.2161663\ttotal: 3.28s\tremaining: 6.78s\n",
      "326:\tlearn: 0.2153758\ttotal: 3.3s\tremaining: 6.79s\n",
      "327:\tlearn: 0.2150186\ttotal: 3.33s\tremaining: 6.81s\n",
      "328:\tlearn: 0.2146548\ttotal: 3.35s\tremaining: 6.84s\n",
      "329:\tlearn: 0.2144292\ttotal: 3.37s\tremaining: 6.85s\n",
      "330:\tlearn: 0.2138550\ttotal: 3.38s\tremaining: 6.84s\n",
      "331:\tlearn: 0.2131742\ttotal: 3.4s\tremaining: 6.83s\n",
      "332:\tlearn: 0.2130229\ttotal: 3.4s\tremaining: 6.82s\n",
      "333:\tlearn: 0.2125855\ttotal: 3.41s\tremaining: 6.8s\n",
      "334:\tlearn: 0.2119672\ttotal: 3.42s\tremaining: 6.79s\n",
      "335:\tlearn: 0.2113344\ttotal: 3.43s\tremaining: 6.78s\n",
      "336:\tlearn: 0.2108544\ttotal: 3.44s\tremaining: 6.77s\n",
      "337:\tlearn: 0.2105556\ttotal: 3.45s\tremaining: 6.75s\n",
      "338:\tlearn: 0.2099583\ttotal: 3.46s\tremaining: 6.74s\n",
      "339:\tlearn: 0.2095073\ttotal: 3.47s\tremaining: 6.73s\n",
      "340:\tlearn: 0.2091795\ttotal: 3.47s\tremaining: 6.71s\n",
      "341:\tlearn: 0.2088800\ttotal: 3.49s\tremaining: 6.72s\n",
      "342:\tlearn: 0.2085370\ttotal: 3.51s\tremaining: 6.72s\n",
      "343:\tlearn: 0.2082187\ttotal: 3.53s\tremaining: 6.73s\n",
      "344:\tlearn: 0.2076278\ttotal: 3.55s\tremaining: 6.74s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "345:\tlearn: 0.2071925\ttotal: 3.57s\tremaining: 6.75s\n",
      "346:\tlearn: 0.2063253\ttotal: 3.6s\tremaining: 6.78s\n",
      "347:\tlearn: 0.2061861\ttotal: 3.63s\tremaining: 6.8s\n",
      "348:\tlearn: 0.2057685\ttotal: 3.65s\tremaining: 6.81s\n",
      "349:\tlearn: 0.2052561\ttotal: 3.67s\tremaining: 6.83s\n",
      "350:\tlearn: 0.2049929\ttotal: 3.69s\tremaining: 6.83s\n",
      "351:\tlearn: 0.2046276\ttotal: 3.7s\tremaining: 6.82s\n",
      "352:\tlearn: 0.2040664\ttotal: 3.71s\tremaining: 6.81s\n",
      "353:\tlearn: 0.2034839\ttotal: 3.72s\tremaining: 6.79s\n",
      "354:\tlearn: 0.2029587\ttotal: 3.73s\tremaining: 6.78s\n",
      "355:\tlearn: 0.2026175\ttotal: 3.74s\tremaining: 6.76s\n",
      "356:\tlearn: 0.2024454\ttotal: 3.75s\tremaining: 6.75s\n",
      "357:\tlearn: 0.2020116\ttotal: 3.76s\tremaining: 6.74s\n",
      "358:\tlearn: 0.2015377\ttotal: 3.77s\tremaining: 6.73s\n",
      "359:\tlearn: 0.2009321\ttotal: 3.78s\tremaining: 6.72s\n",
      "360:\tlearn: 0.2005710\ttotal: 3.79s\tremaining: 6.71s\n",
      "361:\tlearn: 0.2002554\ttotal: 3.81s\tremaining: 6.72s\n",
      "362:\tlearn: 0.1995860\ttotal: 3.84s\tremaining: 6.74s\n",
      "363:\tlearn: 0.1993540\ttotal: 3.88s\tremaining: 6.77s\n",
      "364:\tlearn: 0.1988246\ttotal: 3.9s\tremaining: 6.78s\n",
      "365:\tlearn: 0.1984329\ttotal: 3.92s\tremaining: 6.79s\n",
      "366:\tlearn: 0.1979524\ttotal: 3.94s\tremaining: 6.8s\n",
      "367:\tlearn: 0.1977259\ttotal: 3.96s\tremaining: 6.81s\n",
      "368:\tlearn: 0.1972431\ttotal: 3.99s\tremaining: 6.82s\n",
      "369:\tlearn: 0.1966472\ttotal: 4.01s\tremaining: 6.83s\n",
      "370:\tlearn: 0.1962173\ttotal: 4.03s\tremaining: 6.83s\n",
      "371:\tlearn: 0.1959495\ttotal: 4.04s\tremaining: 6.82s\n",
      "372:\tlearn: 0.1953616\ttotal: 4.05s\tremaining: 6.8s\n",
      "373:\tlearn: 0.1952032\ttotal: 4.06s\tremaining: 6.79s\n",
      "374:\tlearn: 0.1948904\ttotal: 4.07s\tremaining: 6.78s\n",
      "375:\tlearn: 0.1945416\ttotal: 4.08s\tremaining: 6.77s\n",
      "376:\tlearn: 0.1943709\ttotal: 4.11s\tremaining: 6.79s\n",
      "377:\tlearn: 0.1942244\ttotal: 4.13s\tremaining: 6.8s\n",
      "378:\tlearn: 0.1934319\ttotal: 4.15s\tremaining: 6.8s\n",
      "379:\tlearn: 0.1930790\ttotal: 4.18s\tremaining: 6.82s\n",
      "380:\tlearn: 0.1925022\ttotal: 4.21s\tremaining: 6.83s\n",
      "381:\tlearn: 0.1919029\ttotal: 4.23s\tremaining: 6.84s\n",
      "382:\tlearn: 0.1917335\ttotal: 4.24s\tremaining: 6.84s\n",
      "383:\tlearn: 0.1911573\ttotal: 4.26s\tremaining: 6.84s\n",
      "384:\tlearn: 0.1903868\ttotal: 4.29s\tremaining: 6.84s\n",
      "385:\tlearn: 0.1895561\ttotal: 4.31s\tremaining: 6.85s\n",
      "386:\tlearn: 0.1889906\ttotal: 4.32s\tremaining: 6.84s\n",
      "387:\tlearn: 0.1886910\ttotal: 4.33s\tremaining: 6.82s\n",
      "388:\tlearn: 0.1883867\ttotal: 4.33s\tremaining: 6.8s\n",
      "389:\tlearn: 0.1880717\ttotal: 4.34s\tremaining: 6.79s\n",
      "390:\tlearn: 0.1878049\ttotal: 4.35s\tremaining: 6.77s\n",
      "391:\tlearn: 0.1870326\ttotal: 4.36s\tremaining: 6.76s\n",
      "392:\tlearn: 0.1864963\ttotal: 4.37s\tremaining: 6.75s\n",
      "393:\tlearn: 0.1862591\ttotal: 4.38s\tremaining: 6.73s\n",
      "394:\tlearn: 0.1860533\ttotal: 4.39s\tremaining: 6.72s\n",
      "395:\tlearn: 0.1855732\ttotal: 4.41s\tremaining: 6.73s\n",
      "396:\tlearn: 0.1849390\ttotal: 4.43s\tremaining: 6.72s\n",
      "397:\tlearn: 0.1846415\ttotal: 4.46s\tremaining: 6.74s\n",
      "398:\tlearn: 0.1845170\ttotal: 4.47s\tremaining: 6.74s\n",
      "399:\tlearn: 0.1844057\ttotal: 4.51s\tremaining: 6.76s\n",
      "400:\tlearn: 0.1839950\ttotal: 4.53s\tremaining: 6.77s\n",
      "401:\tlearn: 0.1836153\ttotal: 4.55s\tremaining: 6.76s\n",
      "402:\tlearn: 0.1830170\ttotal: 4.57s\tremaining: 6.77s\n",
      "403:\tlearn: 0.1827786\ttotal: 4.59s\tremaining: 6.78s\n",
      "404:\tlearn: 0.1823207\ttotal: 4.61s\tremaining: 6.76s\n",
      "405:\tlearn: 0.1822184\ttotal: 4.62s\tremaining: 6.75s\n",
      "406:\tlearn: 0.1818557\ttotal: 4.63s\tremaining: 6.74s\n",
      "407:\tlearn: 0.1813788\ttotal: 4.64s\tremaining: 6.73s\n",
      "408:\tlearn: 0.1807437\ttotal: 4.65s\tremaining: 6.72s\n",
      "409:\tlearn: 0.1806287\ttotal: 4.66s\tremaining: 6.7s\n",
      "410:\tlearn: 0.1802483\ttotal: 4.67s\tremaining: 6.69s\n",
      "411:\tlearn: 0.1800525\ttotal: 4.68s\tremaining: 6.69s\n",
      "412:\tlearn: 0.1795591\ttotal: 4.7s\tremaining: 6.68s\n",
      "413:\tlearn: 0.1792542\ttotal: 4.72s\tremaining: 6.69s\n",
      "414:\tlearn: 0.1787055\ttotal: 4.75s\tremaining: 6.69s\n",
      "415:\tlearn: 0.1782306\ttotal: 4.77s\tremaining: 6.69s\n",
      "416:\tlearn: 0.1779869\ttotal: 4.79s\tremaining: 6.7s\n",
      "417:\tlearn: 0.1776830\ttotal: 4.81s\tremaining: 6.7s\n",
      "418:\tlearn: 0.1773564\ttotal: 4.83s\tremaining: 6.7s\n",
      "419:\tlearn: 0.1770267\ttotal: 4.86s\tremaining: 6.7s\n",
      "420:\tlearn: 0.1766520\ttotal: 4.87s\tremaining: 6.69s\n",
      "421:\tlearn: 0.1759955\ttotal: 4.89s\tremaining: 6.7s\n",
      "422:\tlearn: 0.1756101\ttotal: 4.91s\tremaining: 6.7s\n",
      "423:\tlearn: 0.1750094\ttotal: 4.93s\tremaining: 6.7s\n",
      "424:\tlearn: 0.1743338\ttotal: 4.96s\tremaining: 6.71s\n",
      "425:\tlearn: 0.1739725\ttotal: 4.97s\tremaining: 6.7s\n",
      "426:\tlearn: 0.1737212\ttotal: 4.99s\tremaining: 6.69s\n",
      "427:\tlearn: 0.1730482\ttotal: 5s\tremaining: 6.68s\n",
      "428:\tlearn: 0.1727249\ttotal: 5.01s\tremaining: 6.67s\n",
      "429:\tlearn: 0.1723311\ttotal: 5.03s\tremaining: 6.67s\n",
      "430:\tlearn: 0.1719309\ttotal: 5.05s\tremaining: 6.67s\n",
      "431:\tlearn: 0.1714920\ttotal: 5.07s\tremaining: 6.66s\n",
      "432:\tlearn: 0.1712311\ttotal: 5.09s\tremaining: 6.67s\n",
      "433:\tlearn: 0.1709559\ttotal: 5.12s\tremaining: 6.68s\n",
      "434:\tlearn: 0.1705419\ttotal: 5.15s\tremaining: 6.69s\n",
      "435:\tlearn: 0.1703489\ttotal: 5.17s\tremaining: 6.69s\n",
      "436:\tlearn: 0.1700235\ttotal: 5.2s\tremaining: 6.69s\n",
      "437:\tlearn: 0.1696952\ttotal: 5.22s\tremaining: 6.69s\n",
      "438:\tlearn: 0.1690422\ttotal: 5.24s\tremaining: 6.69s\n",
      "439:\tlearn: 0.1683726\ttotal: 5.25s\tremaining: 6.68s\n",
      "440:\tlearn: 0.1679083\ttotal: 5.26s\tremaining: 6.66s\n",
      "441:\tlearn: 0.1676438\ttotal: 5.27s\tremaining: 6.65s\n",
      "442:\tlearn: 0.1672300\ttotal: 5.28s\tremaining: 6.64s\n",
      "443:\tlearn: 0.1669972\ttotal: 5.3s\tremaining: 6.64s\n",
      "444:\tlearn: 0.1665177\ttotal: 5.31s\tremaining: 6.63s\n",
      "445:\tlearn: 0.1659508\ttotal: 5.33s\tremaining: 6.62s\n",
      "446:\tlearn: 0.1657122\ttotal: 5.34s\tremaining: 6.61s\n",
      "447:\tlearn: 0.1653121\ttotal: 5.36s\tremaining: 6.61s\n",
      "448:\tlearn: 0.1651352\ttotal: 5.39s\tremaining: 6.61s\n",
      "449:\tlearn: 0.1647786\ttotal: 5.41s\tremaining: 6.61s\n",
      "450:\tlearn: 0.1644073\ttotal: 5.42s\tremaining: 6.6s\n",
      "451:\tlearn: 0.1640269\ttotal: 5.45s\tremaining: 6.61s\n",
      "452:\tlearn: 0.1637544\ttotal: 5.46s\tremaining: 6.6s\n",
      "453:\tlearn: 0.1633088\ttotal: 5.49s\tremaining: 6.6s\n",
      "454:\tlearn: 0.1630281\ttotal: 5.51s\tremaining: 6.6s\n",
      "455:\tlearn: 0.1625517\ttotal: 5.53s\tremaining: 6.59s\n",
      "456:\tlearn: 0.1622644\ttotal: 5.54s\tremaining: 6.58s\n",
      "457:\tlearn: 0.1616489\ttotal: 5.54s\tremaining: 6.56s\n",
      "458:\tlearn: 0.1613719\ttotal: 5.55s\tremaining: 6.54s\n",
      "459:\tlearn: 0.1610540\ttotal: 5.56s\tremaining: 6.53s\n",
      "460:\tlearn: 0.1607476\ttotal: 5.57s\tremaining: 6.51s\n",
      "461:\tlearn: 0.1603436\ttotal: 5.58s\tremaining: 6.5s\n",
      "462:\tlearn: 0.1599804\ttotal: 5.59s\tremaining: 6.48s\n",
      "463:\tlearn: 0.1591346\ttotal: 5.61s\tremaining: 6.47s\n",
      "464:\tlearn: 0.1589503\ttotal: 5.63s\tremaining: 6.48s\n",
      "465:\tlearn: 0.1586924\ttotal: 5.66s\tremaining: 6.48s\n",
      "466:\tlearn: 0.1584180\ttotal: 5.68s\tremaining: 6.48s\n",
      "467:\tlearn: 0.1579307\ttotal: 5.7s\tremaining: 6.47s\n",
      "468:\tlearn: 0.1575794\ttotal: 5.71s\tremaining: 6.47s\n",
      "469:\tlearn: 0.1569063\ttotal: 5.74s\tremaining: 6.47s\n",
      "470:\tlearn: 0.1566993\ttotal: 5.77s\tremaining: 6.48s\n",
      "471:\tlearn: 0.1564472\ttotal: 5.79s\tremaining: 6.48s\n",
      "472:\tlearn: 0.1559757\ttotal: 5.82s\tremaining: 6.48s\n",
      "473:\tlearn: 0.1557305\ttotal: 5.84s\tremaining: 6.48s\n",
      "474:\tlearn: 0.1555331\ttotal: 5.86s\tremaining: 6.48s\n",
      "475:\tlearn: 0.1551908\ttotal: 5.88s\tremaining: 6.48s\n",
      "476:\tlearn: 0.1548117\ttotal: 5.9s\tremaining: 6.47s\n",
      "477:\tlearn: 0.1546900\ttotal: 5.92s\tremaining: 6.47s\n",
      "478:\tlearn: 0.1543146\ttotal: 5.95s\tremaining: 6.47s\n",
      "479:\tlearn: 0.1541582\ttotal: 5.97s\tremaining: 6.46s\n",
      "480:\tlearn: 0.1537337\ttotal: 5.99s\tremaining: 6.46s\n",
      "481:\tlearn: 0.1535794\ttotal: 6.01s\tremaining: 6.46s\n",
      "482:\tlearn: 0.1532432\ttotal: 6.03s\tremaining: 6.46s\n",
      "483:\tlearn: 0.1530335\ttotal: 6.05s\tremaining: 6.45s\n",
      "484:\tlearn: 0.1527452\ttotal: 6.08s\tremaining: 6.45s\n",
      "485:\tlearn: 0.1523694\ttotal: 6.11s\tremaining: 6.46s\n",
      "486:\tlearn: 0.1522947\ttotal: 6.13s\tremaining: 6.46s\n",
      "487:\tlearn: 0.1519879\ttotal: 6.15s\tremaining: 6.45s\n",
      "488:\tlearn: 0.1516939\ttotal: 6.17s\tremaining: 6.45s\n",
      "489:\tlearn: 0.1513579\ttotal: 6.19s\tremaining: 6.44s\n",
      "490:\tlearn: 0.1508789\ttotal: 6.2s\tremaining: 6.43s\n",
      "491:\tlearn: 0.1503244\ttotal: 6.21s\tremaining: 6.41s\n",
      "492:\tlearn: 0.1501218\ttotal: 6.22s\tremaining: 6.4s\n",
      "493:\tlearn: 0.1499491\ttotal: 6.24s\tremaining: 6.39s\n",
      "494:\tlearn: 0.1496329\ttotal: 6.25s\tremaining: 6.38s\n",
      "495:\tlearn: 0.1495253\ttotal: 6.28s\tremaining: 6.38s\n",
      "496:\tlearn: 0.1491607\ttotal: 6.3s\tremaining: 6.38s\n",
      "497:\tlearn: 0.1490231\ttotal: 6.32s\tremaining: 6.37s\n",
      "498:\tlearn: 0.1488067\ttotal: 6.33s\tremaining: 6.36s\n",
      "499:\tlearn: 0.1484530\ttotal: 6.35s\tremaining: 6.35s\n",
      "500:\tlearn: 0.1483195\ttotal: 6.37s\tremaining: 6.34s\n",
      "501:\tlearn: 0.1482274\ttotal: 6.39s\tremaining: 6.34s\n",
      "502:\tlearn: 0.1480226\ttotal: 6.41s\tremaining: 6.34s\n",
      "503:\tlearn: 0.1476157\ttotal: 6.44s\tremaining: 6.34s\n",
      "504:\tlearn: 0.1472521\ttotal: 6.45s\tremaining: 6.33s\n",
      "505:\tlearn: 0.1471531\ttotal: 6.46s\tremaining: 6.31s\n",
      "506:\tlearn: 0.1469586\ttotal: 6.47s\tremaining: 6.3s\n",
      "507:\tlearn: 0.1465211\ttotal: 6.48s\tremaining: 6.28s\n",
      "508:\tlearn: 0.1459843\ttotal: 6.5s\tremaining: 6.27s\n",
      "509:\tlearn: 0.1456497\ttotal: 6.5s\tremaining: 6.25s\n",
      "510:\tlearn: 0.1454807\ttotal: 6.51s\tremaining: 6.23s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511:\tlearn: 0.1453164\ttotal: 6.53s\tremaining: 6.22s\n",
      "512:\tlearn: 0.1451145\ttotal: 6.54s\tremaining: 6.21s\n",
      "513:\tlearn: 0.1449610\ttotal: 6.55s\tremaining: 6.2s\n",
      "514:\tlearn: 0.1444123\ttotal: 6.56s\tremaining: 6.18s\n",
      "515:\tlearn: 0.1438466\ttotal: 6.58s\tremaining: 6.17s\n",
      "516:\tlearn: 0.1435678\ttotal: 6.6s\tremaining: 6.17s\n",
      "517:\tlearn: 0.1432169\ttotal: 6.62s\tremaining: 6.16s\n",
      "518:\tlearn: 0.1429768\ttotal: 6.64s\tremaining: 6.16s\n",
      "519:\tlearn: 0.1428090\ttotal: 6.67s\tremaining: 6.15s\n",
      "520:\tlearn: 0.1426057\ttotal: 6.69s\tremaining: 6.15s\n",
      "521:\tlearn: 0.1422419\ttotal: 6.71s\tremaining: 6.14s\n",
      "522:\tlearn: 0.1419616\ttotal: 6.73s\tremaining: 6.14s\n",
      "523:\tlearn: 0.1417038\ttotal: 6.76s\tremaining: 6.14s\n",
      "524:\tlearn: 0.1412833\ttotal: 6.78s\tremaining: 6.14s\n",
      "525:\tlearn: 0.1409675\ttotal: 6.79s\tremaining: 6.12s\n",
      "526:\tlearn: 0.1406111\ttotal: 6.8s\tremaining: 6.11s\n",
      "527:\tlearn: 0.1400716\ttotal: 6.81s\tremaining: 6.09s\n",
      "528:\tlearn: 0.1398554\ttotal: 6.82s\tremaining: 6.08s\n",
      "529:\tlearn: 0.1396968\ttotal: 6.83s\tremaining: 6.06s\n",
      "530:\tlearn: 0.1395910\ttotal: 6.84s\tremaining: 6.04s\n",
      "531:\tlearn: 0.1394465\ttotal: 6.85s\tremaining: 6.03s\n",
      "532:\tlearn: 0.1392101\ttotal: 6.87s\tremaining: 6.02s\n",
      "533:\tlearn: 0.1387928\ttotal: 6.89s\tremaining: 6.01s\n",
      "534:\tlearn: 0.1386449\ttotal: 6.9s\tremaining: 6s\n",
      "535:\tlearn: 0.1383532\ttotal: 6.91s\tremaining: 5.98s\n",
      "536:\tlearn: 0.1382010\ttotal: 6.94s\tremaining: 5.98s\n",
      "537:\tlearn: 0.1378462\ttotal: 6.96s\tremaining: 5.98s\n",
      "538:\tlearn: 0.1375858\ttotal: 6.99s\tremaining: 5.97s\n",
      "539:\tlearn: 0.1373114\ttotal: 7.01s\tremaining: 5.97s\n",
      "540:\tlearn: 0.1369591\ttotal: 7.03s\tremaining: 5.96s\n",
      "541:\tlearn: 0.1367214\ttotal: 7.04s\tremaining: 5.95s\n",
      "542:\tlearn: 0.1364716\ttotal: 7.07s\tremaining: 5.95s\n",
      "543:\tlearn: 0.1361963\ttotal: 7.08s\tremaining: 5.93s\n",
      "544:\tlearn: 0.1360518\ttotal: 7.09s\tremaining: 5.92s\n",
      "545:\tlearn: 0.1358639\ttotal: 7.1s\tremaining: 5.9s\n",
      "546:\tlearn: 0.1355744\ttotal: 7.11s\tremaining: 5.89s\n",
      "547:\tlearn: 0.1352049\ttotal: 7.11s\tremaining: 5.87s\n",
      "548:\tlearn: 0.1347670\ttotal: 7.12s\tremaining: 5.85s\n",
      "549:\tlearn: 0.1345353\ttotal: 7.13s\tremaining: 5.83s\n",
      "550:\tlearn: 0.1341215\ttotal: 7.13s\tremaining: 5.81s\n",
      "551:\tlearn: 0.1336212\ttotal: 7.14s\tremaining: 5.79s\n",
      "552:\tlearn: 0.1335389\ttotal: 7.15s\tremaining: 5.78s\n",
      "553:\tlearn: 0.1333987\ttotal: 7.15s\tremaining: 5.76s\n",
      "554:\tlearn: 0.1332079\ttotal: 7.16s\tremaining: 5.74s\n",
      "555:\tlearn: 0.1327592\ttotal: 7.17s\tremaining: 5.72s\n",
      "556:\tlearn: 0.1323031\ttotal: 7.17s\tremaining: 5.71s\n",
      "557:\tlearn: 0.1321074\ttotal: 7.18s\tremaining: 5.69s\n",
      "558:\tlearn: 0.1317815\ttotal: 7.2s\tremaining: 5.68s\n",
      "559:\tlearn: 0.1314720\ttotal: 7.21s\tremaining: 5.67s\n",
      "560:\tlearn: 0.1313319\ttotal: 7.22s\tremaining: 5.65s\n",
      "561:\tlearn: 0.1310842\ttotal: 7.23s\tremaining: 5.64s\n",
      "562:\tlearn: 0.1307425\ttotal: 7.24s\tremaining: 5.62s\n",
      "563:\tlearn: 0.1306477\ttotal: 7.25s\tremaining: 5.6s\n",
      "564:\tlearn: 0.1304219\ttotal: 7.26s\tremaining: 5.59s\n",
      "565:\tlearn: 0.1302384\ttotal: 7.27s\tremaining: 5.57s\n",
      "566:\tlearn: 0.1298034\ttotal: 7.28s\tremaining: 5.56s\n",
      "567:\tlearn: 0.1295575\ttotal: 7.28s\tremaining: 5.54s\n",
      "568:\tlearn: 0.1294550\ttotal: 7.29s\tremaining: 5.52s\n",
      "569:\tlearn: 0.1292291\ttotal: 7.3s\tremaining: 5.5s\n",
      "570:\tlearn: 0.1290910\ttotal: 7.3s\tremaining: 5.49s\n",
      "571:\tlearn: 0.1289546\ttotal: 7.31s\tremaining: 5.47s\n",
      "572:\tlearn: 0.1288100\ttotal: 7.32s\tremaining: 5.45s\n",
      "573:\tlearn: 0.1284630\ttotal: 7.32s\tremaining: 5.43s\n",
      "574:\tlearn: 0.1282270\ttotal: 7.33s\tremaining: 5.42s\n",
      "575:\tlearn: 0.1279482\ttotal: 7.33s\tremaining: 5.4s\n",
      "576:\tlearn: 0.1278442\ttotal: 7.34s\tremaining: 5.38s\n",
      "577:\tlearn: 0.1276848\ttotal: 7.35s\tremaining: 5.37s\n",
      "578:\tlearn: 0.1275541\ttotal: 7.35s\tremaining: 5.35s\n",
      "579:\tlearn: 0.1271250\ttotal: 7.36s\tremaining: 5.33s\n",
      "580:\tlearn: 0.1269219\ttotal: 7.37s\tremaining: 5.31s\n",
      "581:\tlearn: 0.1266495\ttotal: 7.37s\tremaining: 5.3s\n",
      "582:\tlearn: 0.1264218\ttotal: 7.38s\tremaining: 5.28s\n",
      "583:\tlearn: 0.1262586\ttotal: 7.39s\tremaining: 5.26s\n",
      "584:\tlearn: 0.1258422\ttotal: 7.39s\tremaining: 5.25s\n",
      "585:\tlearn: 0.1256010\ttotal: 7.42s\tremaining: 5.24s\n",
      "586:\tlearn: 0.1253351\ttotal: 7.44s\tremaining: 5.23s\n",
      "587:\tlearn: 0.1251547\ttotal: 7.46s\tremaining: 5.23s\n",
      "588:\tlearn: 0.1249753\ttotal: 7.48s\tremaining: 5.22s\n",
      "589:\tlearn: 0.1246906\ttotal: 7.5s\tremaining: 5.21s\n",
      "590:\tlearn: 0.1246053\ttotal: 7.53s\tremaining: 5.21s\n",
      "591:\tlearn: 0.1243990\ttotal: 7.55s\tremaining: 5.2s\n",
      "592:\tlearn: 0.1242215\ttotal: 7.57s\tremaining: 5.19s\n",
      "593:\tlearn: 0.1240740\ttotal: 7.59s\tremaining: 5.19s\n",
      "594:\tlearn: 0.1238472\ttotal: 7.61s\tremaining: 5.18s\n",
      "595:\tlearn: 0.1235524\ttotal: 7.63s\tremaining: 5.17s\n",
      "596:\tlearn: 0.1233241\ttotal: 7.65s\tremaining: 5.17s\n",
      "597:\tlearn: 0.1232098\ttotal: 7.67s\tremaining: 5.16s\n",
      "598:\tlearn: 0.1229879\ttotal: 7.69s\tremaining: 5.15s\n",
      "599:\tlearn: 0.1226219\ttotal: 7.72s\tremaining: 5.15s\n",
      "600:\tlearn: 0.1224469\ttotal: 7.74s\tremaining: 5.14s\n",
      "601:\tlearn: 0.1220752\ttotal: 7.75s\tremaining: 5.12s\n",
      "602:\tlearn: 0.1217553\ttotal: 7.76s\tremaining: 5.11s\n",
      "603:\tlearn: 0.1216281\ttotal: 7.77s\tremaining: 5.09s\n",
      "604:\tlearn: 0.1214172\ttotal: 7.78s\tremaining: 5.08s\n",
      "605:\tlearn: 0.1211499\ttotal: 7.79s\tremaining: 5.07s\n",
      "606:\tlearn: 0.1208607\ttotal: 7.82s\tremaining: 5.06s\n",
      "607:\tlearn: 0.1207165\ttotal: 7.84s\tremaining: 5.05s\n",
      "608:\tlearn: 0.1204340\ttotal: 7.86s\tremaining: 5.05s\n",
      "609:\tlearn: 0.1200925\ttotal: 7.88s\tremaining: 5.03s\n",
      "610:\tlearn: 0.1197325\ttotal: 7.89s\tremaining: 5.03s\n",
      "611:\tlearn: 0.1195567\ttotal: 7.92s\tremaining: 5.02s\n",
      "612:\tlearn: 0.1192117\ttotal: 7.93s\tremaining: 5.01s\n",
      "613:\tlearn: 0.1190103\ttotal: 7.95s\tremaining: 5s\n",
      "614:\tlearn: 0.1185959\ttotal: 7.98s\tremaining: 5s\n",
      "615:\tlearn: 0.1183998\ttotal: 8.01s\tremaining: 4.99s\n",
      "616:\tlearn: 0.1182003\ttotal: 8.02s\tremaining: 4.97s\n",
      "617:\tlearn: 0.1180473\ttotal: 8.03s\tremaining: 4.96s\n",
      "618:\tlearn: 0.1179263\ttotal: 8.03s\tremaining: 4.94s\n",
      "619:\tlearn: 0.1176527\ttotal: 8.05s\tremaining: 4.93s\n",
      "620:\tlearn: 0.1174880\ttotal: 8.06s\tremaining: 4.92s\n",
      "621:\tlearn: 0.1173282\ttotal: 8.09s\tremaining: 4.91s\n",
      "622:\tlearn: 0.1171807\ttotal: 8.1s\tremaining: 4.9s\n",
      "623:\tlearn: 0.1169489\ttotal: 8.11s\tremaining: 4.89s\n",
      "624:\tlearn: 0.1167790\ttotal: 8.12s\tremaining: 4.87s\n",
      "625:\tlearn: 0.1166792\ttotal: 8.14s\tremaining: 4.87s\n",
      "626:\tlearn: 0.1164534\ttotal: 8.17s\tremaining: 4.86s\n",
      "627:\tlearn: 0.1163008\ttotal: 8.19s\tremaining: 4.85s\n",
      "628:\tlearn: 0.1159672\ttotal: 8.21s\tremaining: 4.84s\n",
      "629:\tlearn: 0.1158336\ttotal: 8.24s\tremaining: 4.84s\n",
      "630:\tlearn: 0.1156097\ttotal: 8.25s\tremaining: 4.82s\n",
      "631:\tlearn: 0.1151735\ttotal: 8.27s\tremaining: 4.82s\n",
      "632:\tlearn: 0.1149072\ttotal: 8.29s\tremaining: 4.8s\n",
      "633:\tlearn: 0.1146672\ttotal: 8.31s\tremaining: 4.8s\n",
      "634:\tlearn: 0.1146029\ttotal: 8.33s\tremaining: 4.79s\n",
      "635:\tlearn: 0.1145300\ttotal: 8.34s\tremaining: 4.77s\n",
      "636:\tlearn: 0.1143832\ttotal: 8.35s\tremaining: 4.76s\n",
      "637:\tlearn: 0.1142888\ttotal: 8.36s\tremaining: 4.74s\n",
      "638:\tlearn: 0.1141296\ttotal: 8.37s\tremaining: 4.73s\n",
      "639:\tlearn: 0.1138767\ttotal: 8.38s\tremaining: 4.71s\n",
      "640:\tlearn: 0.1136294\ttotal: 8.38s\tremaining: 4.7s\n",
      "641:\tlearn: 0.1134625\ttotal: 8.39s\tremaining: 4.68s\n",
      "642:\tlearn: 0.1133937\ttotal: 8.41s\tremaining: 4.67s\n",
      "643:\tlearn: 0.1131511\ttotal: 8.44s\tremaining: 4.66s\n",
      "644:\tlearn: 0.1130688\ttotal: 8.46s\tremaining: 4.66s\n",
      "645:\tlearn: 0.1124742\ttotal: 8.49s\tremaining: 4.65s\n",
      "646:\tlearn: 0.1122266\ttotal: 8.52s\tremaining: 4.65s\n",
      "647:\tlearn: 0.1120562\ttotal: 8.54s\tremaining: 4.64s\n",
      "648:\tlearn: 0.1116187\ttotal: 8.55s\tremaining: 4.63s\n",
      "649:\tlearn: 0.1114491\ttotal: 8.58s\tremaining: 4.62s\n",
      "650:\tlearn: 0.1110233\ttotal: 8.6s\tremaining: 4.61s\n",
      "651:\tlearn: 0.1105874\ttotal: 8.62s\tremaining: 4.6s\n",
      "652:\tlearn: 0.1104570\ttotal: 8.64s\tremaining: 4.59s\n",
      "653:\tlearn: 0.1103604\ttotal: 8.65s\tremaining: 4.58s\n",
      "654:\tlearn: 0.1101773\ttotal: 8.67s\tremaining: 4.57s\n",
      "655:\tlearn: 0.1100029\ttotal: 8.68s\tremaining: 4.55s\n",
      "656:\tlearn: 0.1097894\ttotal: 8.69s\tremaining: 4.54s\n",
      "657:\tlearn: 0.1096676\ttotal: 8.71s\tremaining: 4.53s\n",
      "658:\tlearn: 0.1095425\ttotal: 8.73s\tremaining: 4.52s\n",
      "659:\tlearn: 0.1093475\ttotal: 8.74s\tremaining: 4.5s\n",
      "660:\tlearn: 0.1091930\ttotal: 8.75s\tremaining: 4.49s\n",
      "661:\tlearn: 0.1090163\ttotal: 8.77s\tremaining: 4.48s\n",
      "662:\tlearn: 0.1087494\ttotal: 8.79s\tremaining: 4.47s\n",
      "663:\tlearn: 0.1085186\ttotal: 8.81s\tremaining: 4.46s\n",
      "664:\tlearn: 0.1082240\ttotal: 8.84s\tremaining: 4.45s\n",
      "665:\tlearn: 0.1081104\ttotal: 8.86s\tremaining: 4.45s\n",
      "666:\tlearn: 0.1080220\ttotal: 8.9s\tremaining: 4.44s\n",
      "667:\tlearn: 0.1077953\ttotal: 8.91s\tremaining: 4.43s\n",
      "668:\tlearn: 0.1076876\ttotal: 8.92s\tremaining: 4.42s\n",
      "669:\tlearn: 0.1074394\ttotal: 8.95s\tremaining: 4.41s\n",
      "670:\tlearn: 0.1071045\ttotal: 8.96s\tremaining: 4.39s\n",
      "671:\tlearn: 0.1066733\ttotal: 8.96s\tremaining: 4.37s\n",
      "672:\tlearn: 0.1065717\ttotal: 8.97s\tremaining: 4.36s\n",
      "673:\tlearn: 0.1063572\ttotal: 8.98s\tremaining: 4.34s\n",
      "674:\tlearn: 0.1061294\ttotal: 8.99s\tremaining: 4.33s\n",
      "675:\tlearn: 0.1058185\ttotal: 8.99s\tremaining: 4.31s\n",
      "676:\tlearn: 0.1055282\ttotal: 9s\tremaining: 4.29s\n",
      "677:\tlearn: 0.1054341\ttotal: 9.01s\tremaining: 4.28s\n",
      "678:\tlearn: 0.1053442\ttotal: 9.01s\tremaining: 4.26s\n",
      "679:\tlearn: 0.1048600\ttotal: 9.02s\tremaining: 4.24s\n",
      "680:\tlearn: 0.1044570\ttotal: 9.03s\tremaining: 4.23s\n",
      "681:\tlearn: 0.1042386\ttotal: 9.04s\tremaining: 4.21s\n",
      "682:\tlearn: 0.1041077\ttotal: 9.05s\tremaining: 4.2s\n",
      "683:\tlearn: 0.1037557\ttotal: 9.06s\tremaining: 4.18s\n",
      "684:\tlearn: 0.1036095\ttotal: 9.07s\tremaining: 4.17s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "685:\tlearn: 0.1034019\ttotal: 9.09s\tremaining: 4.16s\n",
      "686:\tlearn: 0.1031643\ttotal: 9.13s\tremaining: 4.16s\n",
      "687:\tlearn: 0.1030238\ttotal: 9.16s\tremaining: 4.15s\n",
      "688:\tlearn: 0.1029304\ttotal: 9.18s\tremaining: 4.14s\n",
      "689:\tlearn: 0.1025408\ttotal: 9.2s\tremaining: 4.13s\n",
      "690:\tlearn: 0.1024453\ttotal: 9.22s\tremaining: 4.12s\n",
      "691:\tlearn: 0.1021559\ttotal: 9.24s\tremaining: 4.11s\n",
      "692:\tlearn: 0.1020619\ttotal: 9.25s\tremaining: 4.1s\n",
      "693:\tlearn: 0.1019549\ttotal: 9.27s\tremaining: 4.09s\n",
      "694:\tlearn: 0.1016952\ttotal: 9.29s\tremaining: 4.08s\n",
      "695:\tlearn: 0.1014588\ttotal: 9.31s\tremaining: 4.07s\n",
      "696:\tlearn: 0.1013985\ttotal: 9.33s\tremaining: 4.05s\n",
      "697:\tlearn: 0.1013095\ttotal: 9.35s\tremaining: 4.04s\n",
      "698:\tlearn: 0.1011830\ttotal: 9.37s\tremaining: 4.03s\n",
      "699:\tlearn: 0.1010173\ttotal: 9.38s\tremaining: 4.02s\n",
      "700:\tlearn: 0.1007736\ttotal: 9.39s\tremaining: 4.01s\n",
      "701:\tlearn: 0.1006474\ttotal: 9.41s\tremaining: 3.99s\n",
      "702:\tlearn: 0.1004594\ttotal: 9.42s\tremaining: 3.98s\n",
      "703:\tlearn: 0.1003660\ttotal: 9.44s\tremaining: 3.97s\n",
      "704:\tlearn: 0.1000306\ttotal: 9.47s\tremaining: 3.96s\n",
      "705:\tlearn: 0.0998026\ttotal: 9.49s\tremaining: 3.95s\n",
      "706:\tlearn: 0.0997165\ttotal: 9.5s\tremaining: 3.94s\n",
      "707:\tlearn: 0.0996131\ttotal: 9.52s\tremaining: 3.93s\n",
      "708:\tlearn: 0.0994933\ttotal: 9.55s\tremaining: 3.92s\n",
      "709:\tlearn: 0.0992913\ttotal: 9.57s\tremaining: 3.91s\n",
      "710:\tlearn: 0.0991538\ttotal: 9.6s\tremaining: 3.9s\n",
      "711:\tlearn: 0.0990227\ttotal: 9.61s\tremaining: 3.89s\n",
      "712:\tlearn: 0.0989301\ttotal: 9.62s\tremaining: 3.87s\n",
      "713:\tlearn: 0.0987982\ttotal: 9.63s\tremaining: 3.86s\n",
      "714:\tlearn: 0.0986281\ttotal: 9.64s\tremaining: 3.84s\n",
      "715:\tlearn: 0.0984897\ttotal: 9.65s\tremaining: 3.83s\n",
      "716:\tlearn: 0.0981761\ttotal: 9.65s\tremaining: 3.81s\n",
      "717:\tlearn: 0.0980599\ttotal: 9.66s\tremaining: 3.79s\n",
      "718:\tlearn: 0.0980233\ttotal: 9.68s\tremaining: 3.78s\n",
      "719:\tlearn: 0.0979459\ttotal: 9.69s\tremaining: 3.77s\n",
      "720:\tlearn: 0.0978472\ttotal: 9.7s\tremaining: 3.75s\n",
      "721:\tlearn: 0.0977472\ttotal: 9.71s\tremaining: 3.74s\n",
      "722:\tlearn: 0.0975802\ttotal: 9.71s\tremaining: 3.72s\n",
      "723:\tlearn: 0.0974898\ttotal: 9.74s\tremaining: 3.71s\n",
      "724:\tlearn: 0.0973167\ttotal: 9.76s\tremaining: 3.7s\n",
      "725:\tlearn: 0.0971762\ttotal: 9.79s\tremaining: 3.69s\n",
      "726:\tlearn: 0.0971196\ttotal: 9.81s\tremaining: 3.69s\n",
      "727:\tlearn: 0.0969973\ttotal: 9.84s\tremaining: 3.67s\n",
      "728:\tlearn: 0.0968868\ttotal: 9.86s\tremaining: 3.67s\n",
      "729:\tlearn: 0.0967266\ttotal: 9.88s\tremaining: 3.65s\n",
      "730:\tlearn: 0.0966375\ttotal: 9.9s\tremaining: 3.64s\n",
      "731:\tlearn: 0.0963184\ttotal: 9.92s\tremaining: 3.63s\n",
      "732:\tlearn: 0.0960725\ttotal: 9.93s\tremaining: 3.62s\n",
      "733:\tlearn: 0.0960142\ttotal: 9.96s\tremaining: 3.61s\n",
      "734:\tlearn: 0.0955470\ttotal: 9.97s\tremaining: 3.6s\n",
      "735:\tlearn: 0.0950797\ttotal: 9.98s\tremaining: 3.58s\n",
      "736:\tlearn: 0.0949282\ttotal: 9.99s\tremaining: 3.56s\n",
      "737:\tlearn: 0.0947723\ttotal: 10s\tremaining: 3.55s\n",
      "738:\tlearn: 0.0946147\ttotal: 10s\tremaining: 3.53s\n",
      "739:\tlearn: 0.0945366\ttotal: 10s\tremaining: 3.52s\n",
      "740:\tlearn: 0.0943989\ttotal: 10s\tremaining: 3.5s\n",
      "741:\tlearn: 0.0943603\ttotal: 10s\tremaining: 3.48s\n",
      "742:\tlearn: 0.0942159\ttotal: 10s\tremaining: 3.47s\n",
      "743:\tlearn: 0.0940940\ttotal: 10s\tremaining: 3.45s\n",
      "744:\tlearn: 0.0937378\ttotal: 10s\tremaining: 3.44s\n",
      "745:\tlearn: 0.0935301\ttotal: 10.1s\tremaining: 3.42s\n",
      "746:\tlearn: 0.0932683\ttotal: 10.1s\tremaining: 3.41s\n",
      "747:\tlearn: 0.0932029\ttotal: 10.1s\tremaining: 3.4s\n",
      "748:\tlearn: 0.0930019\ttotal: 10.1s\tremaining: 3.39s\n",
      "749:\tlearn: 0.0928810\ttotal: 10.1s\tremaining: 3.38s\n",
      "750:\tlearn: 0.0926895\ttotal: 10.2s\tremaining: 3.37s\n",
      "751:\tlearn: 0.0925241\ttotal: 10.2s\tremaining: 3.36s\n",
      "752:\tlearn: 0.0924695\ttotal: 10.2s\tremaining: 3.35s\n",
      "753:\tlearn: 0.0922030\ttotal: 10.2s\tremaining: 3.34s\n",
      "754:\tlearn: 0.0920198\ttotal: 10.3s\tremaining: 3.33s\n",
      "755:\tlearn: 0.0919114\ttotal: 10.3s\tremaining: 3.32s\n",
      "756:\tlearn: 0.0916777\ttotal: 10.3s\tremaining: 3.31s\n",
      "757:\tlearn: 0.0915422\ttotal: 10.3s\tremaining: 3.3s\n",
      "758:\tlearn: 0.0914525\ttotal: 10.4s\tremaining: 3.29s\n",
      "759:\tlearn: 0.0912689\ttotal: 10.4s\tremaining: 3.27s\n",
      "760:\tlearn: 0.0911502\ttotal: 10.4s\tremaining: 3.26s\n",
      "761:\tlearn: 0.0909528\ttotal: 10.4s\tremaining: 3.24s\n",
      "762:\tlearn: 0.0908387\ttotal: 10.4s\tremaining: 3.23s\n",
      "763:\tlearn: 0.0907607\ttotal: 10.4s\tremaining: 3.22s\n",
      "764:\tlearn: 0.0906788\ttotal: 10.4s\tremaining: 3.2s\n",
      "765:\tlearn: 0.0903717\ttotal: 10.4s\tremaining: 3.19s\n",
      "766:\tlearn: 0.0900685\ttotal: 10.4s\tremaining: 3.17s\n",
      "767:\tlearn: 0.0897297\ttotal: 10.4s\tremaining: 3.15s\n",
      "768:\tlearn: 0.0896324\ttotal: 10.4s\tremaining: 3.14s\n",
      "769:\tlearn: 0.0893140\ttotal: 10.5s\tremaining: 3.12s\n",
      "770:\tlearn: 0.0892419\ttotal: 10.5s\tremaining: 3.11s\n",
      "771:\tlearn: 0.0890780\ttotal: 10.5s\tremaining: 3.09s\n",
      "772:\tlearn: 0.0888929\ttotal: 10.5s\tremaining: 3.08s\n",
      "773:\tlearn: 0.0887146\ttotal: 10.5s\tremaining: 3.06s\n",
      "774:\tlearn: 0.0885580\ttotal: 10.5s\tremaining: 3.04s\n",
      "775:\tlearn: 0.0884246\ttotal: 10.5s\tremaining: 3.03s\n",
      "776:\tlearn: 0.0883280\ttotal: 10.5s\tremaining: 3.01s\n",
      "777:\tlearn: 0.0881279\ttotal: 10.5s\tremaining: 3s\n",
      "778:\tlearn: 0.0879910\ttotal: 10.5s\tremaining: 2.98s\n",
      "779:\tlearn: 0.0878247\ttotal: 10.5s\tremaining: 2.97s\n",
      "780:\tlearn: 0.0876735\ttotal: 10.5s\tremaining: 2.95s\n",
      "781:\tlearn: 0.0873833\ttotal: 10.5s\tremaining: 2.94s\n",
      "782:\tlearn: 0.0873373\ttotal: 10.5s\tremaining: 2.92s\n",
      "783:\tlearn: 0.0872577\ttotal: 10.5s\tremaining: 2.9s\n",
      "784:\tlearn: 0.0871873\ttotal: 10.6s\tremaining: 2.89s\n",
      "785:\tlearn: 0.0869742\ttotal: 10.6s\tremaining: 2.87s\n",
      "786:\tlearn: 0.0866774\ttotal: 10.6s\tremaining: 2.86s\n",
      "787:\tlearn: 0.0864152\ttotal: 10.6s\tremaining: 2.85s\n",
      "788:\tlearn: 0.0863000\ttotal: 10.6s\tremaining: 2.83s\n",
      "789:\tlearn: 0.0861219\ttotal: 10.6s\tremaining: 2.82s\n",
      "790:\tlearn: 0.0859698\ttotal: 10.6s\tremaining: 2.81s\n",
      "791:\tlearn: 0.0858338\ttotal: 10.6s\tremaining: 2.79s\n",
      "792:\tlearn: 0.0856480\ttotal: 10.6s\tremaining: 2.78s\n",
      "793:\tlearn: 0.0854993\ttotal: 10.6s\tremaining: 2.76s\n",
      "794:\tlearn: 0.0853750\ttotal: 10.7s\tremaining: 2.75s\n",
      "795:\tlearn: 0.0852803\ttotal: 10.7s\tremaining: 2.73s\n",
      "796:\tlearn: 0.0851383\ttotal: 10.7s\tremaining: 2.72s\n",
      "797:\tlearn: 0.0848803\ttotal: 10.7s\tremaining: 2.7s\n",
      "798:\tlearn: 0.0847857\ttotal: 10.7s\tremaining: 2.69s\n",
      "799:\tlearn: 0.0845747\ttotal: 10.7s\tremaining: 2.67s\n",
      "800:\tlearn: 0.0843265\ttotal: 10.7s\tremaining: 2.66s\n",
      "801:\tlearn: 0.0841154\ttotal: 10.7s\tremaining: 2.64s\n",
      "802:\tlearn: 0.0840086\ttotal: 10.7s\tremaining: 2.63s\n",
      "803:\tlearn: 0.0838897\ttotal: 10.7s\tremaining: 2.61s\n",
      "804:\tlearn: 0.0836459\ttotal: 10.7s\tremaining: 2.6s\n",
      "805:\tlearn: 0.0833264\ttotal: 10.7s\tremaining: 2.58s\n",
      "806:\tlearn: 0.0830341\ttotal: 10.7s\tremaining: 2.57s\n",
      "807:\tlearn: 0.0828313\ttotal: 10.7s\tremaining: 2.55s\n",
      "808:\tlearn: 0.0827029\ttotal: 10.7s\tremaining: 2.54s\n",
      "809:\tlearn: 0.0825280\ttotal: 10.7s\tremaining: 2.52s\n",
      "810:\tlearn: 0.0823808\ttotal: 10.8s\tremaining: 2.51s\n",
      "811:\tlearn: 0.0821937\ttotal: 10.8s\tremaining: 2.49s\n",
      "812:\tlearn: 0.0820557\ttotal: 10.8s\tremaining: 2.48s\n",
      "813:\tlearn: 0.0820009\ttotal: 10.8s\tremaining: 2.46s\n",
      "814:\tlearn: 0.0819242\ttotal: 10.8s\tremaining: 2.45s\n",
      "815:\tlearn: 0.0817680\ttotal: 10.8s\tremaining: 2.44s\n",
      "816:\tlearn: 0.0815899\ttotal: 10.8s\tremaining: 2.42s\n",
      "817:\tlearn: 0.0814389\ttotal: 10.8s\tremaining: 2.41s\n",
      "818:\tlearn: 0.0813556\ttotal: 10.8s\tremaining: 2.4s\n",
      "819:\tlearn: 0.0813239\ttotal: 10.9s\tremaining: 2.38s\n",
      "820:\tlearn: 0.0812237\ttotal: 10.9s\tremaining: 2.37s\n",
      "821:\tlearn: 0.0811366\ttotal: 10.9s\tremaining: 2.35s\n",
      "822:\tlearn: 0.0810453\ttotal: 10.9s\tremaining: 2.34s\n",
      "823:\tlearn: 0.0809417\ttotal: 10.9s\tremaining: 2.33s\n",
      "824:\tlearn: 0.0808936\ttotal: 10.9s\tremaining: 2.32s\n",
      "825:\tlearn: 0.0808374\ttotal: 11s\tremaining: 2.31s\n",
      "826:\tlearn: 0.0806321\ttotal: 11s\tremaining: 2.3s\n",
      "827:\tlearn: 0.0805657\ttotal: 11s\tremaining: 2.29s\n",
      "828:\tlearn: 0.0805445\ttotal: 11s\tremaining: 2.28s\n",
      "829:\tlearn: 0.0805286\ttotal: 11.1s\tremaining: 2.26s\n",
      "830:\tlearn: 0.0803566\ttotal: 11.1s\tremaining: 2.25s\n",
      "831:\tlearn: 0.0802564\ttotal: 11.1s\tremaining: 2.24s\n",
      "832:\tlearn: 0.0801005\ttotal: 11.1s\tremaining: 2.23s\n",
      "833:\tlearn: 0.0799805\ttotal: 11.1s\tremaining: 2.21s\n",
      "834:\tlearn: 0.0799291\ttotal: 11.2s\tremaining: 2.2s\n",
      "835:\tlearn: 0.0797523\ttotal: 11.2s\tremaining: 2.19s\n",
      "836:\tlearn: 0.0796789\ttotal: 11.2s\tremaining: 2.18s\n",
      "837:\tlearn: 0.0794807\ttotal: 11.2s\tremaining: 2.17s\n",
      "838:\tlearn: 0.0794416\ttotal: 11.2s\tremaining: 2.15s\n",
      "839:\tlearn: 0.0793567\ttotal: 11.2s\tremaining: 2.14s\n",
      "840:\tlearn: 0.0792906\ttotal: 11.3s\tremaining: 2.13s\n",
      "841:\tlearn: 0.0791946\ttotal: 11.3s\tremaining: 2.11s\n",
      "842:\tlearn: 0.0790881\ttotal: 11.3s\tremaining: 2.1s\n",
      "843:\tlearn: 0.0789423\ttotal: 11.3s\tremaining: 2.08s\n",
      "844:\tlearn: 0.0787434\ttotal: 11.3s\tremaining: 2.07s\n",
      "845:\tlearn: 0.0785843\ttotal: 11.3s\tremaining: 2.06s\n",
      "846:\tlearn: 0.0785653\ttotal: 11.3s\tremaining: 2.04s\n",
      "847:\tlearn: 0.0783304\ttotal: 11.3s\tremaining: 2.02s\n",
      "848:\tlearn: 0.0781773\ttotal: 11.3s\tremaining: 2.01s\n",
      "849:\tlearn: 0.0780528\ttotal: 11.3s\tremaining: 2s\n",
      "850:\tlearn: 0.0779248\ttotal: 11.3s\tremaining: 1.98s\n",
      "851:\tlearn: 0.0778671\ttotal: 11.3s\tremaining: 1.97s\n",
      "852:\tlearn: 0.0777240\ttotal: 11.3s\tremaining: 1.95s\n",
      "853:\tlearn: 0.0775670\ttotal: 11.3s\tremaining: 1.94s\n",
      "854:\tlearn: 0.0774312\ttotal: 11.3s\tremaining: 1.92s\n",
      "855:\tlearn: 0.0773609\ttotal: 11.4s\tremaining: 1.91s\n",
      "856:\tlearn: 0.0772040\ttotal: 11.4s\tremaining: 1.9s\n",
      "857:\tlearn: 0.0771505\ttotal: 11.4s\tremaining: 1.88s\n",
      "858:\tlearn: 0.0770478\ttotal: 11.4s\tremaining: 1.87s\n",
      "859:\tlearn: 0.0768933\ttotal: 11.4s\tremaining: 1.85s\n",
      "860:\tlearn: 0.0768125\ttotal: 11.4s\tremaining: 1.84s\n",
      "861:\tlearn: 0.0767148\ttotal: 11.4s\tremaining: 1.82s\n",
      "862:\tlearn: 0.0765453\ttotal: 11.4s\tremaining: 1.81s\n",
      "863:\tlearn: 0.0764299\ttotal: 11.4s\tremaining: 1.79s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "864:\tlearn: 0.0763704\ttotal: 11.4s\tremaining: 1.78s\n",
      "865:\tlearn: 0.0761718\ttotal: 11.4s\tremaining: 1.77s\n",
      "866:\tlearn: 0.0759191\ttotal: 11.5s\tremaining: 1.76s\n",
      "867:\tlearn: 0.0758573\ttotal: 11.5s\tremaining: 1.74s\n",
      "868:\tlearn: 0.0756239\ttotal: 11.5s\tremaining: 1.73s\n",
      "869:\tlearn: 0.0755252\ttotal: 11.5s\tremaining: 1.72s\n",
      "870:\tlearn: 0.0754054\ttotal: 11.5s\tremaining: 1.71s\n",
      "871:\tlearn: 0.0752410\ttotal: 11.5s\tremaining: 1.7s\n",
      "872:\tlearn: 0.0750753\ttotal: 11.6s\tremaining: 1.68s\n",
      "873:\tlearn: 0.0749816\ttotal: 11.6s\tremaining: 1.67s\n",
      "874:\tlearn: 0.0748144\ttotal: 11.6s\tremaining: 1.66s\n",
      "875:\tlearn: 0.0747419\ttotal: 11.6s\tremaining: 1.65s\n",
      "876:\tlearn: 0.0746649\ttotal: 11.7s\tremaining: 1.64s\n",
      "877:\tlearn: 0.0745792\ttotal: 11.7s\tremaining: 1.62s\n",
      "878:\tlearn: 0.0744581\ttotal: 11.7s\tremaining: 1.61s\n",
      "879:\tlearn: 0.0743058\ttotal: 11.7s\tremaining: 1.6s\n",
      "880:\tlearn: 0.0741151\ttotal: 11.8s\tremaining: 1.59s\n",
      "881:\tlearn: 0.0740849\ttotal: 11.8s\tremaining: 1.57s\n",
      "882:\tlearn: 0.0740197\ttotal: 11.8s\tremaining: 1.56s\n",
      "883:\tlearn: 0.0738672\ttotal: 11.8s\tremaining: 1.55s\n",
      "884:\tlearn: 0.0737049\ttotal: 11.8s\tremaining: 1.54s\n",
      "885:\tlearn: 0.0735862\ttotal: 11.9s\tremaining: 1.52s\n",
      "886:\tlearn: 0.0735611\ttotal: 11.9s\tremaining: 1.51s\n",
      "887:\tlearn: 0.0734392\ttotal: 11.9s\tremaining: 1.5s\n",
      "888:\tlearn: 0.0733241\ttotal: 11.9s\tremaining: 1.49s\n",
      "889:\tlearn: 0.0732605\ttotal: 12s\tremaining: 1.48s\n",
      "890:\tlearn: 0.0731309\ttotal: 12s\tremaining: 1.47s\n",
      "891:\tlearn: 0.0730277\ttotal: 12s\tremaining: 1.45s\n",
      "892:\tlearn: 0.0729295\ttotal: 12s\tremaining: 1.44s\n",
      "893:\tlearn: 0.0728671\ttotal: 12.1s\tremaining: 1.43s\n",
      "894:\tlearn: 0.0727996\ttotal: 12.1s\tremaining: 1.42s\n",
      "895:\tlearn: 0.0726214\ttotal: 12.1s\tremaining: 1.4s\n",
      "896:\tlearn: 0.0725317\ttotal: 12.1s\tremaining: 1.39s\n",
      "897:\tlearn: 0.0724443\ttotal: 12.1s\tremaining: 1.38s\n",
      "898:\tlearn: 0.0723725\ttotal: 12.1s\tremaining: 1.36s\n",
      "899:\tlearn: 0.0723436\ttotal: 12.1s\tremaining: 1.35s\n",
      "900:\tlearn: 0.0723079\ttotal: 12.1s\tremaining: 1.33s\n",
      "901:\tlearn: 0.0721422\ttotal: 12.1s\tremaining: 1.32s\n",
      "902:\tlearn: 0.0720238\ttotal: 12.1s\tremaining: 1.3s\n",
      "903:\tlearn: 0.0718437\ttotal: 12.1s\tremaining: 1.29s\n",
      "904:\tlearn: 0.0717296\ttotal: 12.2s\tremaining: 1.27s\n",
      "905:\tlearn: 0.0714933\ttotal: 12.2s\tremaining: 1.26s\n",
      "906:\tlearn: 0.0713306\ttotal: 12.2s\tremaining: 1.25s\n",
      "907:\tlearn: 0.0712879\ttotal: 12.2s\tremaining: 1.23s\n",
      "908:\tlearn: 0.0710939\ttotal: 12.2s\tremaining: 1.22s\n",
      "909:\tlearn: 0.0708771\ttotal: 12.2s\tremaining: 1.21s\n",
      "910:\tlearn: 0.0707484\ttotal: 12.2s\tremaining: 1.19s\n",
      "911:\tlearn: 0.0707016\ttotal: 12.2s\tremaining: 1.18s\n",
      "912:\tlearn: 0.0705777\ttotal: 12.2s\tremaining: 1.16s\n",
      "913:\tlearn: 0.0704868\ttotal: 12.2s\tremaining: 1.15s\n",
      "914:\tlearn: 0.0704153\ttotal: 12.2s\tremaining: 1.14s\n",
      "915:\tlearn: 0.0702349\ttotal: 12.2s\tremaining: 1.12s\n",
      "916:\tlearn: 0.0701136\ttotal: 12.2s\tremaining: 1.11s\n",
      "917:\tlearn: 0.0699482\ttotal: 12.2s\tremaining: 1.09s\n",
      "918:\tlearn: 0.0698660\ttotal: 12.2s\tremaining: 1.08s\n",
      "919:\tlearn: 0.0696972\ttotal: 12.3s\tremaining: 1.06s\n",
      "920:\tlearn: 0.0696765\ttotal: 12.3s\tremaining: 1.05s\n",
      "921:\tlearn: 0.0695529\ttotal: 12.3s\tremaining: 1.04s\n",
      "922:\tlearn: 0.0694597\ttotal: 12.3s\tremaining: 1.02s\n",
      "923:\tlearn: 0.0693124\ttotal: 12.3s\tremaining: 1.01s\n",
      "924:\tlearn: 0.0691870\ttotal: 12.3s\tremaining: 999ms\n",
      "925:\tlearn: 0.0691278\ttotal: 12.3s\tremaining: 987ms\n",
      "926:\tlearn: 0.0690026\ttotal: 12.4s\tremaining: 974ms\n",
      "927:\tlearn: 0.0688746\ttotal: 12.4s\tremaining: 963ms\n",
      "928:\tlearn: 0.0686816\ttotal: 12.4s\tremaining: 950ms\n",
      "929:\tlearn: 0.0685777\ttotal: 12.5s\tremaining: 938ms\n",
      "930:\tlearn: 0.0684222\ttotal: 12.5s\tremaining: 924ms\n",
      "931:\tlearn: 0.0683625\ttotal: 12.5s\tremaining: 911ms\n",
      "932:\tlearn: 0.0681075\ttotal: 12.5s\tremaining: 899ms\n",
      "933:\tlearn: 0.0680871\ttotal: 12.5s\tremaining: 886ms\n",
      "934:\tlearn: 0.0679382\ttotal: 12.6s\tremaining: 874ms\n",
      "935:\tlearn: 0.0677640\ttotal: 12.6s\tremaining: 860ms\n",
      "936:\tlearn: 0.0677032\ttotal: 12.6s\tremaining: 848ms\n",
      "937:\tlearn: 0.0675737\ttotal: 12.6s\tremaining: 835ms\n",
      "938:\tlearn: 0.0674924\ttotal: 12.6s\tremaining: 822ms\n",
      "939:\tlearn: 0.0673574\ttotal: 12.7s\tremaining: 809ms\n",
      "940:\tlearn: 0.0673016\ttotal: 12.7s\tremaining: 795ms\n",
      "941:\tlearn: 0.0672383\ttotal: 12.7s\tremaining: 782ms\n",
      "942:\tlearn: 0.0671547\ttotal: 12.7s\tremaining: 768ms\n",
      "943:\tlearn: 0.0670576\ttotal: 12.7s\tremaining: 755ms\n",
      "944:\tlearn: 0.0669996\ttotal: 12.7s\tremaining: 741ms\n",
      "945:\tlearn: 0.0669102\ttotal: 12.7s\tremaining: 727ms\n",
      "946:\tlearn: 0.0668132\ttotal: 12.7s\tremaining: 713ms\n",
      "947:\tlearn: 0.0667462\ttotal: 12.8s\tremaining: 700ms\n",
      "948:\tlearn: 0.0667191\ttotal: 12.8s\tremaining: 686ms\n",
      "949:\tlearn: 0.0666544\ttotal: 12.8s\tremaining: 673ms\n",
      "950:\tlearn: 0.0665963\ttotal: 12.8s\tremaining: 660ms\n",
      "951:\tlearn: 0.0664913\ttotal: 12.8s\tremaining: 647ms\n",
      "952:\tlearn: 0.0664091\ttotal: 12.9s\tremaining: 634ms\n",
      "953:\tlearn: 0.0663148\ttotal: 12.9s\tremaining: 621ms\n",
      "954:\tlearn: 0.0662518\ttotal: 12.9s\tremaining: 608ms\n",
      "955:\tlearn: 0.0661956\ttotal: 12.9s\tremaining: 595ms\n",
      "956:\tlearn: 0.0660616\ttotal: 13s\tremaining: 582ms\n",
      "957:\tlearn: 0.0659638\ttotal: 13s\tremaining: 569ms\n",
      "958:\tlearn: 0.0659367\ttotal: 13s\tremaining: 556ms\n",
      "959:\tlearn: 0.0657919\ttotal: 13s\tremaining: 543ms\n",
      "960:\tlearn: 0.0657328\ttotal: 13.1s\tremaining: 530ms\n",
      "961:\tlearn: 0.0655895\ttotal: 13.1s\tremaining: 516ms\n",
      "962:\tlearn: 0.0654931\ttotal: 13.1s\tremaining: 503ms\n",
      "963:\tlearn: 0.0654042\ttotal: 13.1s\tremaining: 489ms\n",
      "964:\tlearn: 0.0653469\ttotal: 13.1s\tremaining: 475ms\n",
      "965:\tlearn: 0.0652250\ttotal: 13.1s\tremaining: 462ms\n",
      "966:\tlearn: 0.0650585\ttotal: 13.1s\tremaining: 448ms\n",
      "967:\tlearn: 0.0648389\ttotal: 13.1s\tremaining: 434ms\n",
      "968:\tlearn: 0.0648151\ttotal: 13.1s\tremaining: 421ms\n",
      "969:\tlearn: 0.0647432\ttotal: 13.2s\tremaining: 407ms\n",
      "970:\tlearn: 0.0646698\ttotal: 13.2s\tremaining: 393ms\n",
      "971:\tlearn: 0.0646509\ttotal: 13.2s\tremaining: 379ms\n",
      "972:\tlearn: 0.0646041\ttotal: 13.2s\tremaining: 366ms\n",
      "973:\tlearn: 0.0645396\ttotal: 13.2s\tremaining: 353ms\n",
      "974:\tlearn: 0.0644137\ttotal: 13.2s\tremaining: 339ms\n",
      "975:\tlearn: 0.0642845\ttotal: 13.3s\tremaining: 326ms\n",
      "976:\tlearn: 0.0640492\ttotal: 13.3s\tremaining: 313ms\n",
      "977:\tlearn: 0.0639830\ttotal: 13.3s\tremaining: 300ms\n",
      "978:\tlearn: 0.0639074\ttotal: 13.3s\tremaining: 286ms\n",
      "979:\tlearn: 0.0638432\ttotal: 13.4s\tremaining: 273ms\n",
      "980:\tlearn: 0.0637184\ttotal: 13.4s\tremaining: 259ms\n",
      "981:\tlearn: 0.0635798\ttotal: 13.4s\tremaining: 246ms\n",
      "982:\tlearn: 0.0634566\ttotal: 13.4s\tremaining: 232ms\n",
      "983:\tlearn: 0.0633815\ttotal: 13.4s\tremaining: 218ms\n",
      "984:\tlearn: 0.0632859\ttotal: 13.4s\tremaining: 205ms\n",
      "985:\tlearn: 0.0631421\ttotal: 13.4s\tremaining: 191ms\n",
      "986:\tlearn: 0.0628592\ttotal: 13.5s\tremaining: 177ms\n",
      "987:\tlearn: 0.0627961\ttotal: 13.5s\tremaining: 164ms\n",
      "988:\tlearn: 0.0627450\ttotal: 13.5s\tremaining: 150ms\n",
      "989:\tlearn: 0.0627058\ttotal: 13.5s\tremaining: 136ms\n",
      "990:\tlearn: 0.0625833\ttotal: 13.5s\tremaining: 122ms\n",
      "991:\tlearn: 0.0625504\ttotal: 13.5s\tremaining: 109ms\n",
      "992:\tlearn: 0.0623730\ttotal: 13.5s\tremaining: 95.2ms\n",
      "993:\tlearn: 0.0622756\ttotal: 13.5s\tremaining: 81.6ms\n",
      "994:\tlearn: 0.0621510\ttotal: 13.5s\tremaining: 68ms\n",
      "995:\tlearn: 0.0620589\ttotal: 13.6s\tremaining: 54.5ms\n",
      "996:\tlearn: 0.0619714\ttotal: 13.6s\tremaining: 41ms\n",
      "997:\tlearn: 0.0618620\ttotal: 13.6s\tremaining: 27.3ms\n",
      "998:\tlearn: 0.0617866\ttotal: 13.7s\tremaining: 13.7ms\n",
      "999:\tlearn: 0.0617084\ttotal: 13.7s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.77922077922077926"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "model = CatBoostClassifier()\n",
    "model.fit(X_train,Y_train)\n",
    "model.score(X_test,Y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package catboost:\n",
      "\n",
      "NAME\n",
      "    catboost\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    _catboost\n",
      "    core\n",
      "    datasets\n",
      "    eval (package)\n",
      "    gpu (package)\n",
      "    utils\n",
      "    version\n",
      "    widget (package)\n",
      "\n",
      "CLASSES\n",
      "    _catboost._CatBoostBase(builtins.object)\n",
      "        catboost.core.CatBoost\n",
      "            catboost.core.CatBoostClassifier\n",
      "            catboost.core.CatBoostRegressor\n",
      "    _catboost._PoolBase(builtins.object)\n",
      "        catboost.core.Pool\n",
      "    builtins.Exception(builtins.BaseException)\n",
      "        _catboost.CatboostError\n",
      "    ipywidgets.widgets.domwidget.DOMWidget(ipywidgets.widgets.widget.Widget)\n",
      "        catboost.widget.ipythonwidget.MetricVisualizer\n",
      "    \n",
      "    class CatBoost(_catboost._CatBoostBase)\n",
      "     |  CatBoost model, that contains training, prediction and evaluation.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      CatBoost\n",
      "     |      _catboost._CatBoostBase\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, params=None, model_file=None)\n",
      "     |      Initialize the CatBoost.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : dict\n",
      "     |          Parameters for CatBoost.\n",
      "     |          If  None, all params are set to their defaults.\n",
      "     |          If  dict, overriding parameters present in dict.\n",
      "     |      \n",
      "     |      model_file : string, optional (default=None)\n",
      "     |          If string, giving the path to the file with input model.\n",
      "     |  \n",
      "     |  create_metric_calcer(self, metrics, ntree_start=0, ntree_end=0, eval_period=1, thread_count=-1, tmp_dir=None)\n",
      "     |      Create batch metric calcer. Could be used to aggregate metric on several pools\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |          Same as in eval_metrics except data\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |          BatchMetricCalcer object\n",
      "     |      \n",
      "     |      Usage example\n",
      "     |      -------\n",
      "     |      # Large dataset is partitioned into parts [part1, part2]\n",
      "     |      model.fit(params)\n",
      "     |      batch_calcer = model.create_metric_calcer(['Logloss'])\n",
      "     |      batch_calcer.add_pool(part1)\n",
      "     |      batch_calcer.add_pool(part2)\n",
      "     |      metrics = batch_calcer.eval_metrics()\n",
      "     |  \n",
      "     |  eval_metrics(self, data, metrics, ntree_start=0, ntree_end=0, eval_period=1, thread_count=-1, tmp_dir=None, plot=False)\n",
      "     |      Calculate metrics.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      data : catboost.Pool\n",
      "     |          Data to eval metrics.\n",
      "     |      \n",
      "     |      metrics : list of strings\n",
      "     |          List of eval metrics.\n",
      "     |      \n",
      "     |      ntree_start: int, optional (default=0)\n",
      "     |          Model is applyed on the interval [ntree_start, ntree_end) (zero-based indexing).\n",
      "     |      \n",
      "     |      ntree_end: int, optional (default=0)\n",
      "     |          Model is applyed on the interval [ntree_start, ntree_end) (zero-based indexing).\n",
      "     |          If value equals to 0 this parameter is ignored and ntree_end equal to tree_count_.\n",
      "     |      \n",
      "     |      eval_period: int, optional (default=1)\n",
      "     |          Model is applyed on the interval [ntree_start, ntree_end) with the step eval_period (zero-based indexing).\n",
      "     |      \n",
      "     |      thread_count : int (default=-1)\n",
      "     |          The number of threads to use when applying the model.\n",
      "     |          Allows you to optimize the speed of execution. This parameter doesn't affect results.\n",
      "     |          If -1, then the number of threads is set to the number of cores.\n",
      "     |      \n",
      "     |      tmp_dir : string (default=None)\n",
      "     |          The name of the temporary directory for intermediate results.\n",
      "     |          If None, then the name will be generated.\n",
      "     |      \n",
      "     |      plot : bool, optional (default=False)\n",
      "     |          If True, drow train and eval error in Jupyter notebook\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      prediction : dict: metric -> array of shape [(ntree_end - ntree_start) / eval_period]\n",
      "     |  \n",
      "     |  fit(self, X, y=None, cat_features=None, pairs=None, sample_weight=None, group_id=None, subgroup_id=None, pairs_weight=None, baseline=None, use_best_model=None, eval_set=None, verbose=None, logging_level=None, plot=False, column_description=None, verbose_eval=None)\n",
      "     |      Fit the CatBoost model.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : catboost.Pool or list or numpy.array or pandas.DataFrame or pandas.Series or string.\n",
      "     |          If not catboost.Pool, 2 dimensional Feature matrix or string - file with dataset.\n",
      "     |      \n",
      "     |      y : list or numpy.array or pandas.DataFrame or pandas.Series, optional (default=None)\n",
      "     |          Labels, 1 dimensional array like.\n",
      "     |          Use only if X is not catboost.Pool.\n",
      "     |      \n",
      "     |      cat_features : list or numpy.array, optional (default=None)\n",
      "     |          If not None, giving the list of Categ columns indices.\n",
      "     |          Use only if X is not catboost.Pool.\n",
      "     |      \n",
      "     |      pairs : list or numpy.array or pandas.DataFrame\n",
      "     |          The pairs description.\n",
      "     |          If list or numpy.arrays or pandas.DataFrame, giving 2 dimensional.\n",
      "     |          The shape should be Nx2, where N is the pairs' count. The first element of pair is\n",
      "     |          the index of winner object in training set. The second element of pair is\n",
      "     |          the index of loser object in training set.\n",
      "     |      \n",
      "     |      sample_weight : list or numpy.array or pandas.DataFrame or pandas.Series, optional (default=None)\n",
      "     |          Instance weights, 1 dimensional array like.\n",
      "     |      \n",
      "     |      group_id : list or numpy.array, optional (default=None)\n",
      "     |          group id for each instance.\n",
      "     |          If not None, giving 1 dimensional array like data.\n",
      "     |          Use only if X is not catboost.Pool.\n",
      "     |      \n",
      "     |      subgroup_id : list or numpy.array, optional (default=None)\n",
      "     |          subgroup id for each instance.\n",
      "     |          If not None, giving 1 dimensional array like data.\n",
      "     |          Use only if X is not catboost.Pool.\n",
      "     |      \n",
      "     |      pairs_weight : list or numpy.array, optional (default=None)\n",
      "     |          Weight for each pair.\n",
      "     |          If not None, giving 1 dimensional array like pairs.\n",
      "     |      \n",
      "     |      baseline : list or numpy.array, optional (default=None)\n",
      "     |          If not None, giving 2 dimensional array like data.\n",
      "     |          Use only if X is not catboost.Pool.\n",
      "     |      \n",
      "     |      use_best_model : bool, optional (default=None)\n",
      "     |          Flag to use best model\n",
      "     |      \n",
      "     |      eval_set : catboost.Pool or list, optional (default=None)\n",
      "     |          A list of (X, y) tuple pairs to use as a validation set for\n",
      "     |          early-stopping\n",
      "     |      \n",
      "     |      logging_level : string, optional (default=None)\n",
      "     |          Possible values:\n",
      "     |              - 'Silent'\n",
      "     |              - 'Verbose'\n",
      "     |              - 'Info'\n",
      "     |              - 'Debug'\n",
      "     |      \n",
      "     |      verbose : bool or int\n",
      "     |          If verbose is bool, then if set to True, logging_level is set to Verbose,\n",
      "     |          if set to False, logging_level is set to Silent.\n",
      "     |          If verbose is int, metric_period is set to verbose value and\n",
      "     |          logging_level is set to Verbose.\n",
      "     |      \n",
      "     |      verbose_eval : bool or int\n",
      "     |          Synonym for verbose. Only one of these parameters should be set.\n",
      "     |      \n",
      "     |      plot : bool, optional (default=False)\n",
      "     |          If True, drow train and eval error in Jupyter notebook\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      model : CatBoost\n",
      "     |  \n",
      "     |  get_cat_feature_indices(self)\n",
      "     |  \n",
      "     |  get_feature_importance(self, data, thread_count=-1, fstr_type='FeatureImportance')\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      data : catboost.Pool\n",
      "     |          Data to get feature importance.\n",
      "     |      \n",
      "     |      thread_count : int, optional (default=-1)\n",
      "     |          Number of threads.\n",
      "     |          If -1, then the number of threads is set to the number of cores.\n",
      "     |      \n",
      "     |      fstr_type : string, optional (default='FeatureImportance')\n",
      "     |          Possible values:\n",
      "     |              - FeatureImportance\n",
      "     |                  Calculate score for every feature.\n",
      "     |              - Interaction\n",
      "     |                  Calculate pairwise score between every feature.\n",
      "     |              - Doc\n",
      "     |                  Calculate score for every feature in every object.\n",
      "     |              - ShapValues\n",
      "     |                  Calculate SHAP Values for every object.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      feature_importances : array of shape = [n_features]\n",
      "     |  \n",
      "     |  get_object_importance(self, pool, train_pool, top_size=-1, ostr_type='Average', update_method='SinglePoint', importance_values_sign='All', thread_count=-1)\n",
      "     |      This is the implementation of the LeafInfluence algorithm from the following paper:\n",
      "     |      https://arxiv.org/pdf/1802.06640.pdf\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      pool : Pool\n",
      "     |          The pool for which you want to evaluate the object importances.\n",
      "     |      \n",
      "     |      train_pool : Pool\n",
      "     |          The pool on which the model was trained.\n",
      "     |      \n",
      "     |      top_size : int (default=-1)\n",
      "     |          Method returns the result of the top_size most important train objects.\n",
      "     |          If -1, then the top size is not limited.\n",
      "     |      \n",
      "     |      ostr_type : string, optional (default='Average')\n",
      "     |          Possible values:\n",
      "     |              - Average (Method returns the mean train objects scores for all input objects)\n",
      "     |              - PerObject (Method returns the train objects scores for every input object)\n",
      "     |      \n",
      "     |      importance_values_sign : string, optional (default='All')\n",
      "     |          Method returns only Positive, Negative or All values.\n",
      "     |          Possible values:\n",
      "     |              - Positive\n",
      "     |              - Negative\n",
      "     |              - All\n",
      "     |      \n",
      "     |      update_method : string, optional (default='SinglePoint')\n",
      "     |          Possible values:\n",
      "     |              - SinglePoint\n",
      "     |              - TopKLeaves (It is posible to set top size : TopKLeaves:top=2)\n",
      "     |              - AllPoints\n",
      "     |          Description of the update set methods are given in section 3.1.3 of the paper.\n",
      "     |      \n",
      "     |      thread_count : int, optional (default=-1)\n",
      "     |          Number of threads.\n",
      "     |          If -1, then the number of threads is set to the number of cores.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      object_importances : tuple of two arrays (indices and scores) of shape = [top_size]\n",
      "     |  \n",
      "     |  get_param(self, key)\n",
      "     |      Get param value from CatBoost model.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      key : string\n",
      "     |          The key to get param value from.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      value :\n",
      "     |          The param value of the key, returns None if param do not exist.\n",
      "     |  \n",
      "     |  get_params(self, deep=True)\n",
      "     |      Get all params from CatBoost model.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : dict\n",
      "     |          Dictionary of {param_key: param_value}.\n",
      "     |  \n",
      "     |  load_model(self, fname, format='catboost')\n",
      "     |      Load model from a file.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      fname : string\n",
      "     |          Input file name.\n",
      "     |  \n",
      "     |  predict(self, data, prediction_type='RawFormulaVal', ntree_start=0, ntree_end=0, thread_count=-1, verbose=None)\n",
      "     |      Predict with data.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      data : catboost.Pool or list or numpy.array or pandas.DataFrame or pandas.Series\n",
      "     |          Data to predict.\n",
      "     |      \n",
      "     |      prediction_type : string, optional (default='RawFormulaVal')\n",
      "     |          Can be:\n",
      "     |          - 'RawFormulaVal' : return raw value.\n",
      "     |          - 'Class' : return majority vote class.\n",
      "     |          - 'Probability' : return probability for every class.\n",
      "     |      \n",
      "     |      ntree_start: int, optional (default=0)\n",
      "     |          Model is applyed on the interval [ntree_start, ntree_end) (zero-based indexing).\n",
      "     |      \n",
      "     |      ntree_end: int, optional (default=0)\n",
      "     |          Model is applyed on the interval [ntree_start, ntree_end) (zero-based indexing).\n",
      "     |          If value equals to 0 this parameter is ignored and ntree_end equal to tree_count_.\n",
      "     |      \n",
      "     |      thread_count : int (default=-1)\n",
      "     |          The number of threads to use when applying the model.\n",
      "     |          Allows you to optimize the speed of execution. This parameter doesn't affect results.\n",
      "     |          If -1, then the number of threads is set to the number of cores.\n",
      "     |      \n",
      "     |      verbose : bool, optional (default=False)\n",
      "     |          If True, writes the evaluation metric measured set to stderr.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      prediction : numpy.array\n",
      "     |  \n",
      "     |  save_model(self, fname, format='cbm', export_parameters=None)\n",
      "     |      Save the model to a file.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      fname : string\n",
      "     |          Output file name.\n",
      "     |      format : string\n",
      "     |          Either 'cbm' for catboost binary format, or 'coreml' to export into Apple CoreML format, or 'cpp' to export as C++ code, or 'python' to export as Python code.\n",
      "     |      export_parameters : dict\n",
      "     |          Parameters for CoreML export:\n",
      "     |              * prediction_type : string - either 'probability' or 'raw'\n",
      "     |              * coreml_description : string\n",
      "     |              * coreml_model_version : string\n",
      "     |              * coreml_model_author : string\n",
      "     |              * coreml_model_license: string\n",
      "     |  \n",
      "     |  set_params(self, **params)\n",
      "     |      Set parameters into CatBoost model.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      **params : key=value format\n",
      "     |          List of key=value paris. Example: model.set_params(iterations=500, thread_count=2).\n",
      "     |  \n",
      "     |  shrink(self, ntree_end, ntree_start=0)\n",
      "     |      Shrink the model.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      ntree_end: int\n",
      "     |          Leave the trees with indices from the interval [ntree_start, ntree_end) (zero-based indexing).\n",
      "     |      ntree_start: int, optional (default=0)\n",
      "     |          Leave the trees with indices from the interval [ntree_start, ntree_end) (zero-based indexing).\n",
      "     |  \n",
      "     |  staged_predict(self, data, prediction_type='RawFormulaVal', ntree_start=0, ntree_end=0, eval_period=1, thread_count=-1, verbose=None)\n",
      "     |      Predict target at each stage for data.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      data : catboost.Pool or list or numpy.array or pandas.DataFrame or pandas.Series\n",
      "     |          Data to predict.\n",
      "     |      \n",
      "     |      prediction_type : string, optional (default='RawFormulaVal')\n",
      "     |          Can be:\n",
      "     |          - 'RawFormulaVal' : return raw value.\n",
      "     |          - 'Class' : return majority vote class.\n",
      "     |          - 'Probability' : return probability for every class.\n",
      "     |      \n",
      "     |      ntree_start: int, optional (default=0)\n",
      "     |          Model is applyed on the interval [ntree_start, ntree_end) with the step eval_period (zero-based indexing).\n",
      "     |      \n",
      "     |      ntree_end: int, optional (default=0)\n",
      "     |          Model is applyed on the interval [ntree_start, ntree_end) with the step eval_period (zero-based indexing).\n",
      "     |          If value equals to 0 this parameter is ignored and ntree_end equal to tree_count_.\n",
      "     |      \n",
      "     |      eval_period: int, optional (default=1)\n",
      "     |          Model is applyed on the interval [ntree_start, ntree_end) with the step eval_period (zero-based indexing).\n",
      "     |      \n",
      "     |      thread_count : int (default=-1)\n",
      "     |          The number of threads to use when applying the model.\n",
      "     |          Allows you to optimize the speed of execution. This parameter doesn't affect results.\n",
      "     |          If -1, then the number of threads is set to the number of cores.\n",
      "     |      \n",
      "     |      verbose : bool\n",
      "     |          If True, writes the evaluation metric measured set to stderr.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      prediction : generator numpy.array for each iteration\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  feature_importances_\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from _catboost._CatBoostBase:\n",
      "     |  \n",
      "     |  __copy__(self)\n",
      "     |  \n",
      "     |  __deepcopy__(self, _)\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |  \n",
      "     |  copy(self)\n",
      "     |  \n",
      "     |  get_test_eval(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from _catboost._CatBoostBase:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  is_fitted_\n",
      "     |  \n",
      "     |  random_seed_\n",
      "     |  \n",
      "     |  tree_count_\n",
      "    \n",
      "    class CatBoostClassifier(CatBoost)\n",
      "     |  Implementation of the scikit-learn API for CatBoost classification.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  iterations : int, [default=500]\n",
      "     |      Max count of trees.\n",
      "     |      range: [1,+inf]\n",
      "     |  learning_rate : float, [default=0.03]\n",
      "     |      Step size shrinkage used in update to prevents overfitting.\n",
      "     |      range: (0,1]\n",
      "     |  depth : int, [default=6]\n",
      "     |      Depth of a tree. All trees are the same depth.\n",
      "     |      range: [1,+inf]\n",
      "     |  l2_leaf_reg : int, [default=3]\n",
      "     |      L2 regularization term on weights.\n",
      "     |      range: [0,+inf]\n",
      "     |  model_size_reg : int, [default=None]\n",
      "     |      Model size regularization coefficient.\n",
      "     |      range: [0,+inf]\n",
      "     |  rsm : float, [default=None]\n",
      "     |      Subsample ratio of columns when constructing each tree.\n",
      "     |      range: (0,1]\n",
      "     |  loss_function : string, [default='Logloss']\n",
      "     |      Possible values:\n",
      "     |          - 'Logloss'\n",
      "     |          - 'CrossEntropy'\n",
      "     |          - 'MultiClass'\n",
      "     |          - 'MultiClassOneVsAll'\n",
      "     |  border_count : int, [default=32]\n",
      "     |      The number of partitions for Num features. Used in the preliminary calculation.\n",
      "     |      range: (0,+inf]\n",
      "     |  feature_border_type : string, [default='MinEntropy']\n",
      "     |      Type of binarization target. Used only in Reggression tasks.\n",
      "     |      Possible values:\n",
      "     |          - 'Median'\n",
      "     |          - 'UniformAndQuantiles'\n",
      "     |          - 'GreedyLogSum'\n",
      "     |          - 'MaxLogSum'\n",
      "     |          - 'MinEntropy'\n",
      "     |  fold_permutation_block_size : int, [default=1]\n",
      "     |      To accelerate the learning.\n",
      "     |      The recommended value is within [1, 256]. On small samples, must be set to 1.\n",
      "     |      range: [1,+inf]\n",
      "     |  od_pval : float, [default=None]\n",
      "     |      Use overfitting detector to stop training when reaching a specified threshold.\n",
      "     |      Can be used only with eval_set.\n",
      "     |      range: [0,1]\n",
      "     |  od_wait : int, [default=None]\n",
      "     |      Number of iterations which overfitting detector will wait after new best error.\n",
      "     |  od_type : string, [default=None]\n",
      "     |      Type of overfitting detector which will be used in program.\n",
      "     |      Posible values:\n",
      "     |          - 'IncToDec'\n",
      "     |          - 'Iter'\n",
      "     |      For 'Iter' type od_pval must not be set.\n",
      "     |      If None, then od_type=IncToDec.\n",
      "     |  nan_mode : string, [default=None]\n",
      "     |      Way to process nan-values.\n",
      "     |      Possible values:\n",
      "     |          - 'Forbidden' - raises an exception if there is nan value in dataset.\n",
      "     |          - 'Min' - each nan float feature will be processed as minimum value from dataset.\n",
      "     |          - 'Max' - each nan float feature will be processed as maximum value from dataset.\n",
      "     |      If None, then nan_mode=Min.\n",
      "     |  counter_calc_method : string, [default=None]\n",
      "     |      The method used to calculate counters for dataset with Counter type.\n",
      "     |      Possible values:\n",
      "     |          - 'PrefixTest' - only objects up to current in the test dataset are considered\n",
      "     |          - 'FullTest' - all objects are considered in the test dataset\n",
      "     |          - 'SkipTest' - Objects from test dataset are not considered\n",
      "     |          - 'Full' - all objects are considered for both learn and test dataset\n",
      "     |      If None, then counter_calc_method=PrefixTest.\n",
      "     |  leaf_estimation_iterations : int, [default=None]\n",
      "     |      The number of steps in the gradient when calculating the values in the leaves.\n",
      "     |      If None, then leaf_estimation_iterations=1.\n",
      "     |      range: [1,+inf]\n",
      "     |  leaf_estimation_method : string, [default='Gradient']\n",
      "     |      The method used to calculate the values in the leaves.\n",
      "     |      Possible values:\n",
      "     |          - 'Newton'\n",
      "     |          - 'Gradient'\n",
      "     |  thread_count : int, [default=None]\n",
      "     |      Number of parallel threads used to run CatBoost.\n",
      "     |      If None, then the number of thread is set to the number of cores.\n",
      "     |      range: [1,+inf]\n",
      "     |  random_seed : int, [default=None]\n",
      "     |      Random number seed.\n",
      "     |      If None, used random number.\n",
      "     |      range: [0,+inf]\n",
      "     |  use_best_model : bool, [default=None]\n",
      "     |      To limit the number of trees in predict() using information about the optimal value of the error function.\n",
      "     |      Can be used only with eval_set.\n",
      "     |  logging_level : string, [default='Verbose']\n",
      "     |      Possible values:\n",
      "     |          - 'Silent'\n",
      "     |          - 'Verbose'\n",
      "     |          - 'Info'\n",
      "     |          - 'Debug'\n",
      "     |  metric_period : int, [default=1]\n",
      "     |      The frequency of iterations to print the information to stdout. The value should be a positive integer.\n",
      "     |  simple_ctr: list of strings, [default=None]\n",
      "     |      Binarization settings for categorical features.\n",
      "     |          Format : see documentation\n",
      "     |          Example: ['Borders:CtrBorderCount=5:Prior=0:Prior=0.5', 'BinarizedTargetMeanValue:TargetBorderCount=10:TargetBorderType=MinEntropy', ...]\n",
      "     |          CTR types:\n",
      "     |              CPU and GPU\n",
      "     |              - 'Borders'\n",
      "     |              - 'Buckets'\n",
      "     |              CPU only\n",
      "     |              - 'BinarizedTargetMeanValue'\n",
      "     |              - 'Counter'\n",
      "     |              GPU only\n",
      "     |              - 'FloatTargetMeanValue'\n",
      "     |              - 'FeatureFreq'\n",
      "     |          Number_of_borders, binarization type, target borders and binarizations, priors are optional parametrs\n",
      "     |  combinations_ctr: list of strings, [default=None]\n",
      "     |  per_feature_ctr: list of strings, [default=None]\n",
      "     |  ctr_leaf_count_limit : int, [default=None]\n",
      "     |      The maximum number of leafs with categorical features.\n",
      "     |      If the quantity exceeds the specified value a part of leafs is discarded.\n",
      "     |      The leafs to be discarded are selected as follows:\n",
      "     |          - The leafs are sorted by the frequency of the values.\n",
      "     |          - The top N leafs are selected, where N is the value specified in the parameter.\n",
      "     |          - All leafs starting from N+1 are discarded.\n",
      "     |      This option reduces the resulting model size\n",
      "     |      and the amount of memory required for training.\n",
      "     |      Note that the resulting quality of the model can be affected.\n",
      "     |      range: [1,+inf]\n",
      "     |  store_all_simple_ctr : bool, [default=None]\n",
      "     |      Ignore categorical features, which are not used in feature combinations,\n",
      "     |      when choosing candidates for exclusion.\n",
      "     |      Use this parameter with ctr_leaf_count_limit only.\n",
      "     |  max_ctr_complexity : int, [default=4]\n",
      "     |      The maximum number of Categ features that can be combined.\n",
      "     |      range: [0,+inf]\n",
      "     |  has_time : bool, [default=False]\n",
      "     |      To use the order in which objects are represented in the input data\n",
      "     |      (do not perform a random permutation on the stages of converting\n",
      "     |      the Categ features to Num and the choice of a tree structure).\n",
      "     |  classes_count : int, [default=None]\n",
      "     |      The upper limit for the numeric class label.\n",
      "     |      Defines the number of classes for multiclassification.\n",
      "     |      Only non-negative integers can be specified.\n",
      "     |      The given integer should be greater than any of the target values.\n",
      "     |      If this parameter is specified the labels for all classes in the input dataset\n",
      "     |      should be smaller than the given value.\n",
      "     |  class_weights : list of floats, [default=None]\n",
      "     |      Classes weights. The values are used as multipliers for the object weights.\n",
      "     |      If None, all classes are supposed to have weight one.\n",
      "     |      Number of classes indicated by classes_count and class_weights should be the same.\n",
      "     |  one_hot_max_size : int, [default=None]\n",
      "     |      Convert the feature to float\n",
      "     |      if the number of different values that it takes exceeds the specified value.\n",
      "     |      Ctrs are not calculated for such features.\n",
      "     |  random_strength : float, [default=1]\n",
      "     |      Score standard deviation multiplier.\n",
      "     |  name : string, [default='experiment']\n",
      "     |      The name that should be displayed in the visualization tools.\n",
      "     |  ignored_features : list, [default=None]\n",
      "     |      Indices of features that should be excluded when training.\n",
      "     |  train_dir : string, [default=None]\n",
      "     |      The directory in which you want to record generated in the process of learning files.\n",
      "     |  custom_metric : object, [default=None]\n",
      "     |      To use your own metric function.\n",
      "     |  custom_loss: alias to custom_metric, deprecated and will be removed in future\n",
      "     |  eval_metric : string or object, [default=None]\n",
      "     |      To optimize your custom metric in loss.\n",
      "     |  bagging_temperature : float, [default=None]\n",
      "     |      Controls intensity of Bayesian bagging. The higher the temperature the more aggressive bagging is.\n",
      "     |      Typical values are in range [0, 1] (0 - no bagging, 1 - default).\n",
      "     |  save_snapshot : bool, [default=None]\n",
      "     |      Enable progress snapshoting for restoring progress after crashes or interruptions\n",
      "     |  snapshot_file : string, [default=None]\n",
      "     |      Learn progress snapshot file path, if None will use default filename\n",
      "     |  fold_len_multiplier : float, [default=None]\n",
      "     |      Fold length multiplier. Should be greater than 1\n",
      "     |  used_ram_limit : int, [default=None]\n",
      "     |      Try to limit used memory (limit value in bytes).\n",
      "     |      WARNING: Currently this option affects CTR memory usage only.\n",
      "     |  gpu_ram_part : int, [default=0.95]\n",
      "     |      How much of the GPU RAM to use for training.\n",
      "     |  allow_writing_files : bool, [default=True]\n",
      "     |      If this flag is set to False, no files with different diagnostic info will be created during training.\n",
      "     |      With this flag no snapshotting can be done. Plus visualisation will not\n",
      "     |      work, because visualisation uses files that are created and updated during training.\n",
      "     |  final_ctr_computation_mode : string, [default='Default']\n",
      "     |      Possible values:\n",
      "     |          - 'Default' - Compute final ctrs for all pools.\n",
      "     |          - 'Skip' - Skip final ctr computation. WARNING: model without ctrs can't be applied.\n",
      "     |  approx_on_full_history : bool, [default=False]\n",
      "     |      If this flag is set to True, each approximated value is calculated using all the preceeding rows in the fold (slower, more accurate).\n",
      "     |      If this flag is set to False, each approximated value is calculated using only the beginning 1/fold_len_multiplier fraction of the fold (faster, slightly less accurate).\n",
      "     |  boosting_type : string, default value depends on object count and feature count in train dataset and on learning mode.\n",
      "     |      Boosting scheme.\n",
      "     |      Possible values:\n",
      "     |          - 'Ordered' - Gives better quality, but may slow down the training.\n",
      "     |          - 'Plain' - The classic gradient boosting scheme. May result in quality degradation, but does not slow down the training.\n",
      "     |  task_type : string, [default=None]\n",
      "     |      The calcer type used to train the model.\n",
      "     |      Possible values:\n",
      "     |          - 'CPU'\n",
      "     |          - 'GPU'\n",
      "     |  device_config : string, [default=None], deprecated, use devices instead\n",
      "     |  devices : list or string, [default=None], GPU devices to use.\n",
      "     |      String format is: '0' for 1 device or '0:1:3' for multiple devices or '0-3' for range of devices.\n",
      "     |      List format is : [0] for 1 device or [0,1,3] for multiple devices.\n",
      "     |  \n",
      "     |  bootstrap_type : string, Bayesian, Bernoulli, Poisson.\n",
      "     |      Default bootstrap is Bayesian.\n",
      "     |      Poisson bootstrap is supported only on GPU.\n",
      "     |  \n",
      "     |  subsample : float, [default=None]\n",
      "     |      Sample rate for bagging. This parameter can be used Poisson or Bernoully bootstrap types.\n",
      "     |  \n",
      "     |  max_depth : int, Synonym for depth.\n",
      "     |  \n",
      "     |  n_estimators : int, synonym for iterations.\n",
      "     |  \n",
      "     |  num_trees : int, synonym for iterations.\n",
      "     |  \n",
      "     |  num_boost_round : int, synonym for iterations.\n",
      "     |  \n",
      "     |  colsample_bylevel : float, synonym for rsm.\n",
      "     |  \n",
      "     |  random_state : int, synonym for random_seed.\n",
      "     |  \n",
      "     |  reg_lambda : float, synonym for l2_leaf_reg.\n",
      "     |  \n",
      "     |  objective : string, synonym for loss_function.\n",
      "     |  \n",
      "     |  eta : float, synonym for learning_rate.\n",
      "     |  \n",
      "     |  max_bin : float, synonym for border_count.\n",
      "     |  \n",
      "     |  scale_pos_weight : float, synonym for class_weights.\n",
      "     |      Can be used only for binary classification. Sets weight multiplier for\n",
      "     |      class 1 to scale_pos_weight value.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      CatBoostClassifier\n",
      "     |      CatBoost\n",
      "     |      _catboost._CatBoostBase\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, iterations=None, learning_rate=None, depth=None, l2_leaf_reg=None, model_size_reg=None, rsm=None, loss_function='Logloss', border_count=None, feature_border_type=None, fold_permutation_block_size=None, od_pval=None, od_wait=None, od_type=None, nan_mode=None, counter_calc_method=None, leaf_estimation_iterations=None, leaf_estimation_method=None, thread_count=None, random_seed=None, use_best_model=None, verbose=None, logging_level=None, metric_period=None, ctr_leaf_count_limit=None, store_all_simple_ctr=None, max_ctr_complexity=None, has_time=None, classes_count=None, class_weights=None, one_hot_max_size=None, random_strength=None, name=None, ignored_features=None, train_dir=None, custom_loss=None, custom_metric=None, eval_metric=None, bagging_temperature=None, save_snapshot=None, snapshot_file=None, fold_len_multiplier=None, used_ram_limit=None, gpu_ram_part=None, allow_writing_files=None, final_ctr_computation_mode=None, approx_on_full_history=None, boosting_type=None, simple_ctr=None, combinations_ctr=None, per_feature_ctr=None, ctr_description=None, task_type=None, device_config=None, devices=None, bootstrap_type=None, subsample=None, max_depth=None, n_estimators=None, num_boost_round=None, num_trees=None, colsample_bylevel=None, random_state=None, reg_lambda=None, objective=None, eta=None, max_bin=None, scale_pos_weight=None, gpu_cat_features_storage=None, data_partition=None, **kwargs)\n",
      "     |      Initialize the CatBoost.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : dict\n",
      "     |          Parameters for CatBoost.\n",
      "     |          If  None, all params are set to their defaults.\n",
      "     |          If  dict, overriding parameters present in dict.\n",
      "     |      \n",
      "     |      model_file : string, optional (default=None)\n",
      "     |          If string, giving the path to the file with input model.\n",
      "     |  \n",
      "     |  fit(self, X, y=None, cat_features=None, sample_weight=None, baseline=None, use_best_model=None, eval_set=None, verbose=None, logging_level=None, plot=False, column_description=None, verbose_eval=None)\n",
      "     |      Fit the CatBoost model.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : catboost.Pool or list or numpy.array or pandas.DataFrame or pandas.Series\n",
      "     |          If not catboost.Pool, 2 dimensional Feature matrix or string - file with dataset.\n",
      "     |      \n",
      "     |      y : list or numpy.array or pandas.DataFrame or pandas.Series, optional (default=None)\n",
      "     |          Labels, 1 dimensional array like.\n",
      "     |          Use only if X is not catboost.Pool.\n",
      "     |      \n",
      "     |      cat_features : list or numpy.array, optional (default=None)\n",
      "     |          If not None, giving the list of Categ columns indices.\n",
      "     |          Use only if X is not catboost.Pool.\n",
      "     |      \n",
      "     |      sample_weight : list or numpy.array or pandas.DataFrame or pandas.Series, optional (default=None)\n",
      "     |          Instance weights, 1 dimensional array like.\n",
      "     |      \n",
      "     |      baseline : list or numpy.array, optional (default=None)\n",
      "     |          If not None, giving 2 dimensional array like data.\n",
      "     |          Use only if X is not catboost.Pool.\n",
      "     |      \n",
      "     |      use_best_model : bool, optional (default=None)\n",
      "     |          Flag to use best model\n",
      "     |      \n",
      "     |      eval_set : catboost.Pool or list, optional (default=None)\n",
      "     |          A list of (X, y) tuple pairs to use as a validation set for\n",
      "     |          early-stopping\n",
      "     |      \n",
      "     |      verbose : bool or int\n",
      "     |          If verbose is bool, then if set to True, logging_level is set to Verbose,\n",
      "     |          if set to False, logging_level is set to Silent.\n",
      "     |          If verbose is int, metric_period is set to verbose value and\n",
      "     |          logging_level is set to Verbose.\n",
      "     |      \n",
      "     |      logging_level : string, optional (default=None)\n",
      "     |          Possible values:\n",
      "     |              - 'Silent'\n",
      "     |              - 'Verbose'\n",
      "     |              - 'Info'\n",
      "     |              - 'Debug'\n",
      "     |      \n",
      "     |      plot : bool, optional (default=False)\n",
      "     |          If True, drow train and eval error in Jupyter notebook\n",
      "     |      \n",
      "     |      verbose_eval : bool or int\n",
      "     |          Synonym for verbose. Only one of these parameters should be set.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      model : CatBoost\n",
      "     |  \n",
      "     |  predict(self, data, prediction_type='Class', ntree_start=0, ntree_end=0, thread_count=-1, verbose=None)\n",
      "     |      Predict with data.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      data : catboost.Pool or list or numpy.array or pandas.DataFrame or pandas.Series\n",
      "     |          Data to predict.\n",
      "     |      \n",
      "     |      prediction_type : string, optional (default='Class')\n",
      "     |          Can be:\n",
      "     |          - 'RawFormulaVal' : return raw value.\n",
      "     |          - 'Class' : return majority vote class.\n",
      "     |          - 'Probability' : return probability for every class.\n",
      "     |      \n",
      "     |      ntree_start: int, optional (default=0)\n",
      "     |          Model is applyed on the interval [ntree_start, ntree_end) (zero-based indexing).\n",
      "     |      \n",
      "     |      ntree_end: int, optional (default=0)\n",
      "     |          Model is applyed on the interval [ntree_start, ntree_end) (zero-based indexing).\n",
      "     |          If value equals to 0 this parameter is ignored and ntree_end equal to tree_count_.\n",
      "     |      \n",
      "     |      thread_count : int (default=-1)\n",
      "     |          The number of threads to use when applying the model.\n",
      "     |          Allows you to optimize the speed of execution. This parameter doesn't affect results.\n",
      "     |          If -1, then the number of threads is set to the number of cores.\n",
      "     |      \n",
      "     |      verbose : bool, optional (default=False)\n",
      "     |          If True, writes the evaluation metric measured set to stderr.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      prediction : numpy.array\n",
      "     |  \n",
      "     |  predict_proba(self, data, ntree_start=0, ntree_end=0, thread_count=-1, verbose=None)\n",
      "     |      Predict class probability with data.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      data : catboost.Pool or list or numpy.array or pandas.DataFrame or pandas.Series\n",
      "     |          Data to predict.\n",
      "     |      \n",
      "     |      ntree_start: int, optional (default=0)\n",
      "     |          Model is applyed on the interval [ntree_start, ntree_end) (zero-based indexing).\n",
      "     |      \n",
      "     |      ntree_end: int, optional (default=0)\n",
      "     |          Model is applyed on the interval [ntree_start, ntree_end) (zero-based indexing).\n",
      "     |          If value equals to 0 this parameter is ignored and ntree_end equal to tree_count_.\n",
      "     |      \n",
      "     |      thread_count : int (default=-1)\n",
      "     |          The number of threads to use when applying the model.\n",
      "     |          Allows you to optimize the speed of execution. This parameter doesn't affect results.\n",
      "     |          If -1, then the number of threads is set to the number of cores.\n",
      "     |      \n",
      "     |      verbose : bool\n",
      "     |          If True, writes the evaluation metric measured set to stderr.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      prediction : numpy.array\n",
      "     |  \n",
      "     |  score(self, X, y)\n",
      "     |      Calculate accuracy.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : catboost.Pool or list or numpy.array or pandas.DataFrame or pandas.Series\n",
      "     |          Data to predict.\n",
      "     |      y : list or numpy.array\n",
      "     |          True labels.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      accuracy : float\n",
      "     |  \n",
      "     |  staged_predict(self, data, prediction_type='Class', ntree_start=0, ntree_end=0, eval_period=1, thread_count=-1, verbose=None)\n",
      "     |      Predict target at each stage for data.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      data : catboost.Pool or list or numpy.array or pandas.DataFrame or pandas.Series\n",
      "     |          Data to predict.\n",
      "     |      \n",
      "     |      prediction_type : string, optional (default='Class')\n",
      "     |          Can be:\n",
      "     |          - 'RawFormulaVal' : return raw value.\n",
      "     |          - 'Class' : return majority vote class.\n",
      "     |          - 'Probability' : return probability for every class.\n",
      "     |      \n",
      "     |      ntree_start: int, optional (default=0)\n",
      "     |          Model is applyed on the interval [ntree_start, ntree_end) with the step eval_period (zero-based indexing).\n",
      "     |      \n",
      "     |      ntree_end: int, optional (default=0)\n",
      "     |          Model is applyed on the interval [ntree_start, ntree_end) with the step eval_period (zero-based indexing).\n",
      "     |          If value equals to 0 this parameter is ignored and ntree_end equal to tree_count_.\n",
      "     |      \n",
      "     |      eval_period: int, optional (default=1)\n",
      "     |          Model is applyed on the interval [ntree_start, ntree_end) with the step eval_period (zero-based indexing).\n",
      "     |      \n",
      "     |      thread_count : int (default=-1)\n",
      "     |          The number of threads to use when applying the model.\n",
      "     |          Allows you to optimize the speed of execution. This parameter doesn't affect results.\n",
      "     |          If -1, then the number of threads is set to the number of cores.\n",
      "     |      \n",
      "     |      verbose : bool\n",
      "     |          If True, writes the evaluation metric measured set to stderr.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      prediction : generator numpy.array for each iteration\n",
      "     |  \n",
      "     |  staged_predict_proba(self, data, ntree_start=0, ntree_end=0, eval_period=1, thread_count=-1, verbose=None)\n",
      "     |      Predict classification target at each stage for data.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      data : catboost.Pool or list or numpy.array or pandas.DataFrame or pandas.Series\n",
      "     |          Data to predict.\n",
      "     |      \n",
      "     |      ntree_start: int, optional (default=0)\n",
      "     |          Model is applyed on the interval [ntree_start, ntree_end) with the step eval_period (zero-based indexing).\n",
      "     |      \n",
      "     |      ntree_end: int, optional (default=0)\n",
      "     |          Model is applyed on the interval [ntree_start, ntree_end) with the step eval_period (zero-based indexing).\n",
      "     |          If value equals to 0 this parameter is ignored and ntree_end equal to tree_count_.\n",
      "     |      \n",
      "     |      eval_period: int, optional (default=1)\n",
      "     |          Model is applyed on the interval [ntree_start, ntree_end) with the step eval_period (zero-based indexing).\n",
      "     |      \n",
      "     |      thread_count : int (default=-1)\n",
      "     |          The number of threads to use when applying the model.\n",
      "     |          Allows you to optimize the speed of execution. This parameter doesn't affect results.\n",
      "     |          If -1, then the number of threads is set to the number of cores.\n",
      "     |      \n",
      "     |      verbose : bool\n",
      "     |          If True, writes the evaluation metric measured set to stderr.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      prediction : generator numpy.array for each iteration\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  classes_\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from CatBoost:\n",
      "     |  \n",
      "     |  create_metric_calcer(self, metrics, ntree_start=0, ntree_end=0, eval_period=1, thread_count=-1, tmp_dir=None)\n",
      "     |      Create batch metric calcer. Could be used to aggregate metric on several pools\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |          Same as in eval_metrics except data\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |          BatchMetricCalcer object\n",
      "     |      \n",
      "     |      Usage example\n",
      "     |      -------\n",
      "     |      # Large dataset is partitioned into parts [part1, part2]\n",
      "     |      model.fit(params)\n",
      "     |      batch_calcer = model.create_metric_calcer(['Logloss'])\n",
      "     |      batch_calcer.add_pool(part1)\n",
      "     |      batch_calcer.add_pool(part2)\n",
      "     |      metrics = batch_calcer.eval_metrics()\n",
      "     |  \n",
      "     |  eval_metrics(self, data, metrics, ntree_start=0, ntree_end=0, eval_period=1, thread_count=-1, tmp_dir=None, plot=False)\n",
      "     |      Calculate metrics.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      data : catboost.Pool\n",
      "     |          Data to eval metrics.\n",
      "     |      \n",
      "     |      metrics : list of strings\n",
      "     |          List of eval metrics.\n",
      "     |      \n",
      "     |      ntree_start: int, optional (default=0)\n",
      "     |          Model is applyed on the interval [ntree_start, ntree_end) (zero-based indexing).\n",
      "     |      \n",
      "     |      ntree_end: int, optional (default=0)\n",
      "     |          Model is applyed on the interval [ntree_start, ntree_end) (zero-based indexing).\n",
      "     |          If value equals to 0 this parameter is ignored and ntree_end equal to tree_count_.\n",
      "     |      \n",
      "     |      eval_period: int, optional (default=1)\n",
      "     |          Model is applyed on the interval [ntree_start, ntree_end) with the step eval_period (zero-based indexing).\n",
      "     |      \n",
      "     |      thread_count : int (default=-1)\n",
      "     |          The number of threads to use when applying the model.\n",
      "     |          Allows you to optimize the speed of execution. This parameter doesn't affect results.\n",
      "     |          If -1, then the number of threads is set to the number of cores.\n",
      "     |      \n",
      "     |      tmp_dir : string (default=None)\n",
      "     |          The name of the temporary directory for intermediate results.\n",
      "     |          If None, then the name will be generated.\n",
      "     |      \n",
      "     |      plot : bool, optional (default=False)\n",
      "     |          If True, drow train and eval error in Jupyter notebook\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      prediction : dict: metric -> array of shape [(ntree_end - ntree_start) / eval_period]\n",
      "     |  \n",
      "     |  get_cat_feature_indices(self)\n",
      "     |  \n",
      "     |  get_feature_importance(self, data, thread_count=-1, fstr_type='FeatureImportance')\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      data : catboost.Pool\n",
      "     |          Data to get feature importance.\n",
      "     |      \n",
      "     |      thread_count : int, optional (default=-1)\n",
      "     |          Number of threads.\n",
      "     |          If -1, then the number of threads is set to the number of cores.\n",
      "     |      \n",
      "     |      fstr_type : string, optional (default='FeatureImportance')\n",
      "     |          Possible values:\n",
      "     |              - FeatureImportance\n",
      "     |                  Calculate score for every feature.\n",
      "     |              - Interaction\n",
      "     |                  Calculate pairwise score between every feature.\n",
      "     |              - Doc\n",
      "     |                  Calculate score for every feature in every object.\n",
      "     |              - ShapValues\n",
      "     |                  Calculate SHAP Values for every object.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      feature_importances : array of shape = [n_features]\n",
      "     |  \n",
      "     |  get_object_importance(self, pool, train_pool, top_size=-1, ostr_type='Average', update_method='SinglePoint', importance_values_sign='All', thread_count=-1)\n",
      "     |      This is the implementation of the LeafInfluence algorithm from the following paper:\n",
      "     |      https://arxiv.org/pdf/1802.06640.pdf\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      pool : Pool\n",
      "     |          The pool for which you want to evaluate the object importances.\n",
      "     |      \n",
      "     |      train_pool : Pool\n",
      "     |          The pool on which the model was trained.\n",
      "     |      \n",
      "     |      top_size : int (default=-1)\n",
      "     |          Method returns the result of the top_size most important train objects.\n",
      "     |          If -1, then the top size is not limited.\n",
      "     |      \n",
      "     |      ostr_type : string, optional (default='Average')\n",
      "     |          Possible values:\n",
      "     |              - Average (Method returns the mean train objects scores for all input objects)\n",
      "     |              - PerObject (Method returns the train objects scores for every input object)\n",
      "     |      \n",
      "     |      importance_values_sign : string, optional (default='All')\n",
      "     |          Method returns only Positive, Negative or All values.\n",
      "     |          Possible values:\n",
      "     |              - Positive\n",
      "     |              - Negative\n",
      "     |              - All\n",
      "     |      \n",
      "     |      update_method : string, optional (default='SinglePoint')\n",
      "     |          Possible values:\n",
      "     |              - SinglePoint\n",
      "     |              - TopKLeaves (It is posible to set top size : TopKLeaves:top=2)\n",
      "     |              - AllPoints\n",
      "     |          Description of the update set methods are given in section 3.1.3 of the paper.\n",
      "     |      \n",
      "     |      thread_count : int, optional (default=-1)\n",
      "     |          Number of threads.\n",
      "     |          If -1, then the number of threads is set to the number of cores.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      object_importances : tuple of two arrays (indices and scores) of shape = [top_size]\n",
      "     |  \n",
      "     |  get_param(self, key)\n",
      "     |      Get param value from CatBoost model.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      key : string\n",
      "     |          The key to get param value from.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      value :\n",
      "     |          The param value of the key, returns None if param do not exist.\n",
      "     |  \n",
      "     |  get_params(self, deep=True)\n",
      "     |      Get all params from CatBoost model.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : dict\n",
      "     |          Dictionary of {param_key: param_value}.\n",
      "     |  \n",
      "     |  load_model(self, fname, format='catboost')\n",
      "     |      Load model from a file.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      fname : string\n",
      "     |          Input file name.\n",
      "     |  \n",
      "     |  save_model(self, fname, format='cbm', export_parameters=None)\n",
      "     |      Save the model to a file.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      fname : string\n",
      "     |          Output file name.\n",
      "     |      format : string\n",
      "     |          Either 'cbm' for catboost binary format, or 'coreml' to export into Apple CoreML format, or 'cpp' to export as C++ code, or 'python' to export as Python code.\n",
      "     |      export_parameters : dict\n",
      "     |          Parameters for CoreML export:\n",
      "     |              * prediction_type : string - either 'probability' or 'raw'\n",
      "     |              * coreml_description : string\n",
      "     |              * coreml_model_version : string\n",
      "     |              * coreml_model_author : string\n",
      "     |              * coreml_model_license: string\n",
      "     |  \n",
      "     |  set_params(self, **params)\n",
      "     |      Set parameters into CatBoost model.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      **params : key=value format\n",
      "     |          List of key=value paris. Example: model.set_params(iterations=500, thread_count=2).\n",
      "     |  \n",
      "     |  shrink(self, ntree_end, ntree_start=0)\n",
      "     |      Shrink the model.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      ntree_end: int\n",
      "     |          Leave the trees with indices from the interval [ntree_start, ntree_end) (zero-based indexing).\n",
      "     |      ntree_start: int, optional (default=0)\n",
      "     |          Leave the trees with indices from the interval [ntree_start, ntree_end) (zero-based indexing).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from CatBoost:\n",
      "     |  \n",
      "     |  feature_importances_\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from _catboost._CatBoostBase:\n",
      "     |  \n",
      "     |  __copy__(self)\n",
      "     |  \n",
      "     |  __deepcopy__(self, _)\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |  \n",
      "     |  copy(self)\n",
      "     |  \n",
      "     |  get_test_eval(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from _catboost._CatBoostBase:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  is_fitted_\n",
      "     |  \n",
      "     |  random_seed_\n",
      "     |  \n",
      "     |  tree_count_\n",
      "    \n",
      "    class CatBoostRegressor(CatBoost)\n",
      "     |  Implementation of the scikit-learn API for CatBoost regression.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  Like in CatBoostClassifier, except loss_function, class_weights and\n",
      "     |  classes_count\n",
      "     |  \n",
      "     |  loss_function : string, [default='RMSE']\n",
      "     |      'RMSE'\n",
      "     |      'MAE'\n",
      "     |      'Quantile:alpha=value'\n",
      "     |      'LogLinQuantile:alpha=value'\n",
      "     |      'Poisson'\n",
      "     |      'MAPE'\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      CatBoostRegressor\n",
      "     |      CatBoost\n",
      "     |      _catboost._CatBoostBase\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, iterations=None, learning_rate=None, depth=None, l2_leaf_reg=None, model_size_reg=None, rsm=None, loss_function='RMSE', border_count=None, feature_border_type=None, fold_permutation_block_size=None, od_pval=None, od_wait=None, od_type=None, nan_mode=None, counter_calc_method=None, leaf_estimation_iterations=None, leaf_estimation_method=None, thread_count=None, random_seed=None, use_best_model=None, verbose=None, logging_level=None, metric_period=None, ctr_leaf_count_limit=None, store_all_simple_ctr=None, max_ctr_complexity=None, has_time=None, one_hot_max_size=None, random_strength=None, name=None, ignored_features=None, train_dir=None, custom_metric=None, eval_metric=None, bagging_temperature=None, save_snapshot=None, snapshot_file=None, fold_len_multiplier=None, used_ram_limit=None, gpu_ram_part=None, allow_writing_files=None, final_ctr_computation_mode=None, approx_on_full_history=None, boosting_type=None, simple_ctr=None, combinations_ctr=None, per_feature_ctr=None, ctr_description=None, task_type=None, device_config=None, devices=None, bootstrap_type=None, subsample=None, max_depth=None, n_estimators=None, num_boost_round=None, num_trees=None, colsample_bylevel=None, random_state=None, reg_lambda=None, objective=None, eta=None, max_bin=None, gpu_cat_features_storage=None, data_partition=None, **kwargs)\n",
      "     |      Initialize the CatBoost.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : dict\n",
      "     |          Parameters for CatBoost.\n",
      "     |          If  None, all params are set to their defaults.\n",
      "     |          If  dict, overriding parameters present in dict.\n",
      "     |      \n",
      "     |      model_file : string, optional (default=None)\n",
      "     |          If string, giving the path to the file with input model.\n",
      "     |  \n",
      "     |  fit(self, X, y=None, cat_features=None, sample_weight=None, baseline=None, use_best_model=None, eval_set=None, verbose=None, logging_level=None, plot=False, column_description=None, verbose_eval=None)\n",
      "     |      Fit the CatBoost model.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : catboost.Pool or list or numpy.array or pandas.DataFrame or pandas.Series\n",
      "     |          If not catboost.Pool, 2 dimensional Feature matrix or string - file with dataset.\n",
      "     |      \n",
      "     |      y : list or numpy.array or pandas.DataFrame or pandas.Series, optional (default=None)\n",
      "     |          Labels, 1 dimensional array like.\n",
      "     |          Use only if X is not catboost.Pool.\n",
      "     |      \n",
      "     |      cat_features : list or numpy.array, optional (default=None)\n",
      "     |          If not None, giving the list of Categ columns indices.\n",
      "     |          Use only if X is not catboost.Pool.\n",
      "     |      \n",
      "     |      sample_weight : list or numpy.array or pandas.DataFrame or pandas.Series, optional (default=None)\n",
      "     |          Instance weights, 1 dimensional array like.\n",
      "     |      \n",
      "     |      baseline : list or numpy.array, optional (default=None)\n",
      "     |          If not None, giving 2 dimensional array like data.\n",
      "     |          Use only if X is not catboost.Pool.\n",
      "     |      \n",
      "     |      use_best_model : bool, optional (default=None)\n",
      "     |          Flag to use best model\n",
      "     |      \n",
      "     |      eval_set : catboost.Pool or list, optional (default=None)\n",
      "     |          A list of (X, y) tuple pairs to use as a validation set for\n",
      "     |          early-stopping\n",
      "     |      \n",
      "     |      verbose : bool or int\n",
      "     |          If verbose is bool, then if set to True, logging_level is set to Verbose,\n",
      "     |          if set to False, logging_level is set to Silent.\n",
      "     |          If verbose is int, metric_period is set to verbose value and\n",
      "     |          logging_level is set to Verbose.\n",
      "     |      \n",
      "     |      logging_level : string, optional (default=None)\n",
      "     |          Possible values:\n",
      "     |              - 'Silent'\n",
      "     |              - 'Verbose'\n",
      "     |              - 'Info'\n",
      "     |              - 'Debug'\n",
      "     |      \n",
      "     |      plot : bool, optional (default=False)\n",
      "     |          If True, drow train and eval error in Jupyter notebook\n",
      "     |      \n",
      "     |      verbose_eval : bool or int\n",
      "     |          Synonym for verbose. Only one of these parameters should be set.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      model : CatBoost\n",
      "     |  \n",
      "     |  predict(self, data, ntree_start=0, ntree_end=0, thread_count=-1, verbose=None)\n",
      "     |      Predict with data.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      data : catboost.Pool or list or numpy.array or pandas.DataFrame or pandas.Series\n",
      "     |          Data to predict.\n",
      "     |      \n",
      "     |      ntree_start: int, optional (default=0)\n",
      "     |          Model is applyed on the interval [ntree_start, ntree_end) (zero-based indexing).\n",
      "     |      \n",
      "     |      ntree_end: int, optional (default=0)\n",
      "     |          Model is applyed on the interval [ntree_start, ntree_end) (zero-based indexing).\n",
      "     |          If value equals to 0 this parameter is ignored and ntree_end equal to tree_count_.\n",
      "     |      \n",
      "     |      thread_count : int (default=-1)\n",
      "     |          The number of threads to use when applying the model.\n",
      "     |          Allows you to optimize the speed of execution. This parameter doesn't affect results.\n",
      "     |          If -1, then the number of threads is set to the number of cores.\n",
      "     |      \n",
      "     |      verbose : bool\n",
      "     |          If True, writes the evaluation metric measured set to stderr.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      prediction : numpy.array\n",
      "     |  \n",
      "     |  score(self, X, y)\n",
      "     |      Calculate RMSE.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : catboost.Pool or list or numpy.array or pandas.DataFrame or pandas.Series\n",
      "     |          Data to predict.\n",
      "     |      y : list or numpy.array\n",
      "     |          True labels.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      RMSE : float\n",
      "     |  \n",
      "     |  staged_predict(self, data, ntree_start=0, ntree_end=0, eval_period=1, thread_count=-1, verbose=None)\n",
      "     |      Predict target at each stage for data.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      data : catboost.Pool or list or numpy.array or pandas.DataFrame or pandas.Series\n",
      "     |          Data to predict.\n",
      "     |      \n",
      "     |      ntree_start: int, optional (default=0)\n",
      "     |          Model is applyed on the interval [ntree_start, ntree_end) with the step eval_period (zero-based indexing).\n",
      "     |      \n",
      "     |      ntree_end: int, optional (default=0)\n",
      "     |          Model is applyed on the interval [ntree_start, ntree_end) with the step eval_period (zero-based indexing).\n",
      "     |          If value equals to 0 this parameter is ignored and ntree_end equal to tree_count_.\n",
      "     |      \n",
      "     |      eval_period: int, optional (default=1)\n",
      "     |          Model is applyed on the interval [ntree_start, ntree_end) with the step eval_period (zero-based indexing).\n",
      "     |      \n",
      "     |      thread_count : int (default=-1)\n",
      "     |          The number of threads to use when applying the model.\n",
      "     |          Allows you to optimize the speed of execution. This parameter doesn't affect results.\n",
      "     |          If -1, then the number of threads is set to the number of cores.\n",
      "     |      \n",
      "     |      verbose : bool\n",
      "     |          If True, writes the evaluation metric measured set to stderr.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      prediction : generator numpy.array for each iteration\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from CatBoost:\n",
      "     |  \n",
      "     |  create_metric_calcer(self, metrics, ntree_start=0, ntree_end=0, eval_period=1, thread_count=-1, tmp_dir=None)\n",
      "     |      Create batch metric calcer. Could be used to aggregate metric on several pools\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |          Same as in eval_metrics except data\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |          BatchMetricCalcer object\n",
      "     |      \n",
      "     |      Usage example\n",
      "     |      -------\n",
      "     |      # Large dataset is partitioned into parts [part1, part2]\n",
      "     |      model.fit(params)\n",
      "     |      batch_calcer = model.create_metric_calcer(['Logloss'])\n",
      "     |      batch_calcer.add_pool(part1)\n",
      "     |      batch_calcer.add_pool(part2)\n",
      "     |      metrics = batch_calcer.eval_metrics()\n",
      "     |  \n",
      "     |  eval_metrics(self, data, metrics, ntree_start=0, ntree_end=0, eval_period=1, thread_count=-1, tmp_dir=None, plot=False)\n",
      "     |      Calculate metrics.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      data : catboost.Pool\n",
      "     |          Data to eval metrics.\n",
      "     |      \n",
      "     |      metrics : list of strings\n",
      "     |          List of eval metrics.\n",
      "     |      \n",
      "     |      ntree_start: int, optional (default=0)\n",
      "     |          Model is applyed on the interval [ntree_start, ntree_end) (zero-based indexing).\n",
      "     |      \n",
      "     |      ntree_end: int, optional (default=0)\n",
      "     |          Model is applyed on the interval [ntree_start, ntree_end) (zero-based indexing).\n",
      "     |          If value equals to 0 this parameter is ignored and ntree_end equal to tree_count_.\n",
      "     |      \n",
      "     |      eval_period: int, optional (default=1)\n",
      "     |          Model is applyed on the interval [ntree_start, ntree_end) with the step eval_period (zero-based indexing).\n",
      "     |      \n",
      "     |      thread_count : int (default=-1)\n",
      "     |          The number of threads to use when applying the model.\n",
      "     |          Allows you to optimize the speed of execution. This parameter doesn't affect results.\n",
      "     |          If -1, then the number of threads is set to the number of cores.\n",
      "     |      \n",
      "     |      tmp_dir : string (default=None)\n",
      "     |          The name of the temporary directory for intermediate results.\n",
      "     |          If None, then the name will be generated.\n",
      "     |      \n",
      "     |      plot : bool, optional (default=False)\n",
      "     |          If True, drow train and eval error in Jupyter notebook\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      prediction : dict: metric -> array of shape [(ntree_end - ntree_start) / eval_period]\n",
      "     |  \n",
      "     |  get_cat_feature_indices(self)\n",
      "     |  \n",
      "     |  get_feature_importance(self, data, thread_count=-1, fstr_type='FeatureImportance')\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      data : catboost.Pool\n",
      "     |          Data to get feature importance.\n",
      "     |      \n",
      "     |      thread_count : int, optional (default=-1)\n",
      "     |          Number of threads.\n",
      "     |          If -1, then the number of threads is set to the number of cores.\n",
      "     |      \n",
      "     |      fstr_type : string, optional (default='FeatureImportance')\n",
      "     |          Possible values:\n",
      "     |              - FeatureImportance\n",
      "     |                  Calculate score for every feature.\n",
      "     |              - Interaction\n",
      "     |                  Calculate pairwise score between every feature.\n",
      "     |              - Doc\n",
      "     |                  Calculate score for every feature in every object.\n",
      "     |              - ShapValues\n",
      "     |                  Calculate SHAP Values for every object.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      feature_importances : array of shape = [n_features]\n",
      "     |  \n",
      "     |  get_object_importance(self, pool, train_pool, top_size=-1, ostr_type='Average', update_method='SinglePoint', importance_values_sign='All', thread_count=-1)\n",
      "     |      This is the implementation of the LeafInfluence algorithm from the following paper:\n",
      "     |      https://arxiv.org/pdf/1802.06640.pdf\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      pool : Pool\n",
      "     |          The pool for which you want to evaluate the object importances.\n",
      "     |      \n",
      "     |      train_pool : Pool\n",
      "     |          The pool on which the model was trained.\n",
      "     |      \n",
      "     |      top_size : int (default=-1)\n",
      "     |          Method returns the result of the top_size most important train objects.\n",
      "     |          If -1, then the top size is not limited.\n",
      "     |      \n",
      "     |      ostr_type : string, optional (default='Average')\n",
      "     |          Possible values:\n",
      "     |              - Average (Method returns the mean train objects scores for all input objects)\n",
      "     |              - PerObject (Method returns the train objects scores for every input object)\n",
      "     |      \n",
      "     |      importance_values_sign : string, optional (default='All')\n",
      "     |          Method returns only Positive, Negative or All values.\n",
      "     |          Possible values:\n",
      "     |              - Positive\n",
      "     |              - Negative\n",
      "     |              - All\n",
      "     |      \n",
      "     |      update_method : string, optional (default='SinglePoint')\n",
      "     |          Possible values:\n",
      "     |              - SinglePoint\n",
      "     |              - TopKLeaves (It is posible to set top size : TopKLeaves:top=2)\n",
      "     |              - AllPoints\n",
      "     |          Description of the update set methods are given in section 3.1.3 of the paper.\n",
      "     |      \n",
      "     |      thread_count : int, optional (default=-1)\n",
      "     |          Number of threads.\n",
      "     |          If -1, then the number of threads is set to the number of cores.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      object_importances : tuple of two arrays (indices and scores) of shape = [top_size]\n",
      "     |  \n",
      "     |  get_param(self, key)\n",
      "     |      Get param value from CatBoost model.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      key : string\n",
      "     |          The key to get param value from.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      value :\n",
      "     |          The param value of the key, returns None if param do not exist.\n",
      "     |  \n",
      "     |  get_params(self, deep=True)\n",
      "     |      Get all params from CatBoost model.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : dict\n",
      "     |          Dictionary of {param_key: param_value}.\n",
      "     |  \n",
      "     |  load_model(self, fname, format='catboost')\n",
      "     |      Load model from a file.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      fname : string\n",
      "     |          Input file name.\n",
      "     |  \n",
      "     |  save_model(self, fname, format='cbm', export_parameters=None)\n",
      "     |      Save the model to a file.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      fname : string\n",
      "     |          Output file name.\n",
      "     |      format : string\n",
      "     |          Either 'cbm' for catboost binary format, or 'coreml' to export into Apple CoreML format, or 'cpp' to export as C++ code, or 'python' to export as Python code.\n",
      "     |      export_parameters : dict\n",
      "     |          Parameters for CoreML export:\n",
      "     |              * prediction_type : string - either 'probability' or 'raw'\n",
      "     |              * coreml_description : string\n",
      "     |              * coreml_model_version : string\n",
      "     |              * coreml_model_author : string\n",
      "     |              * coreml_model_license: string\n",
      "     |  \n",
      "     |  set_params(self, **params)\n",
      "     |      Set parameters into CatBoost model.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      **params : key=value format\n",
      "     |          List of key=value paris. Example: model.set_params(iterations=500, thread_count=2).\n",
      "     |  \n",
      "     |  shrink(self, ntree_end, ntree_start=0)\n",
      "     |      Shrink the model.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      ntree_end: int\n",
      "     |          Leave the trees with indices from the interval [ntree_start, ntree_end) (zero-based indexing).\n",
      "     |      ntree_start: int, optional (default=0)\n",
      "     |          Leave the trees with indices from the interval [ntree_start, ntree_end) (zero-based indexing).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from CatBoost:\n",
      "     |  \n",
      "     |  feature_importances_\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from _catboost._CatBoostBase:\n",
      "     |  \n",
      "     |  __copy__(self)\n",
      "     |  \n",
      "     |  __deepcopy__(self, _)\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |  \n",
      "     |  copy(self)\n",
      "     |  \n",
      "     |  get_test_eval(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from _catboost._CatBoostBase:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  is_fitted_\n",
      "     |  \n",
      "     |  random_seed_\n",
      "     |  \n",
      "     |  tree_count_\n",
      "    \n",
      "    class CatboostError(builtins.Exception)\n",
      "     |  Common base class for all non-exit exceptions.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      CatboostError\n",
      "     |      builtins.Exception\n",
      "     |      builtins.BaseException\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.Exception:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.BaseException:\n",
      "     |  \n",
      "     |  __delattr__(self, name, /)\n",
      "     |      Implement delattr(self, name).\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __reduce__(...)\n",
      "     |      helper for pickle\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setattr__(self, name, value, /)\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |  \n",
      "     |  __setstate__(...)\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  with_traceback(...)\n",
      "     |      Exception.with_traceback(tb) --\n",
      "     |      set self.__traceback__ to tb and return self.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from builtins.BaseException:\n",
      "     |  \n",
      "     |  __cause__\n",
      "     |      exception cause\n",
      "     |  \n",
      "     |  __context__\n",
      "     |      exception context\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |  \n",
      "     |  __suppress_context__\n",
      "     |  \n",
      "     |  __traceback__\n",
      "     |  \n",
      "     |  args\n",
      "    \n",
      "    class MetricVisualizer(ipywidgets.widgets.domwidget.DOMWidget)\n",
      "     |  Widget that can be inserted into the DOM\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      MetricVisualizer\n",
      "     |      ipywidgets.widgets.domwidget.DOMWidget\n",
      "     |      ipywidgets.widgets.widget.Widget\n",
      "     |      ipywidgets.widgets.widget.LoggingHasTraits\n",
      "     |      traitlets.traitlets.HasTraits\n",
      "     |      traitlets.traitlets.HasDescriptors\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, train_dirs, subdirs=False)\n",
      "     |      Public constructor\n",
      "     |  \n",
      "     |  start(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  data\n",
      "     |      An instance of a Python dict.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from ipywidgets.widgets.domwidget.DOMWidget:\n",
      "     |  \n",
      "     |  add_class(self, className)\n",
      "     |      Adds a class to the top level element of the widget.\n",
      "     |      \n",
      "     |      Doesn't add the class if it already exists.\n",
      "     |  \n",
      "     |  remove_class(self, className)\n",
      "     |      Removes a class from the top level element of the widget.\n",
      "     |      \n",
      "     |      Doesn't remove the class if it doesn't exist.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from ipywidgets.widgets.domwidget.DOMWidget:\n",
      "     |  \n",
      "     |  layout\n",
      "     |      An instance trait which coerces a dict to an instance.\n",
      "     |      \n",
      "     |      This lets the instance be specified as a dict, which is used\n",
      "     |      to initialize the instance.\n",
      "     |      \n",
      "     |      Also, we default to a trivial instance, even if args and kwargs\n",
      "     |      is not specified.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from ipywidgets.widgets.widget.Widget:\n",
      "     |  \n",
      "     |  __del__(self)\n",
      "     |      Object disposal\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  add_traits(self, **traits)\n",
      "     |      Dynamically add trait attributes to the Widget.\n",
      "     |  \n",
      "     |  close(self)\n",
      "     |      Close method.\n",
      "     |      \n",
      "     |      Closes the underlying comm.\n",
      "     |      When the comm is closed, all of the widget views are automatically\n",
      "     |      removed from the front-end.\n",
      "     |  \n",
      "     |  get_state(self, key=None, drop_defaults=False)\n",
      "     |      Gets the widget state, or a piece of it.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      key : unicode or iterable (optional)\n",
      "     |          A single property's name or iterable of property names to get.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      state : dict of states\n",
      "     |      metadata : dict\n",
      "     |          metadata for each field: {key: metadata}\n",
      "     |  \n",
      "     |  get_view_spec(self)\n",
      "     |  \n",
      "     |  hold_sync(self)\n",
      "     |      Hold syncing any state until the outermost context manager exits\n",
      "     |  \n",
      "     |  notify_change(self, change)\n",
      "     |      Called when a property has changed.\n",
      "     |  \n",
      "     |  on_displayed(self, callback, remove=False)\n",
      "     |      (Un)Register a widget displayed callback.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      callback: method handler\n",
      "     |          Must have a signature of::\n",
      "     |      \n",
      "     |              callback(widget, **kwargs)\n",
      "     |      \n",
      "     |          kwargs from display are passed through without modification.\n",
      "     |      remove: bool\n",
      "     |          True if the callback should be unregistered.\n",
      "     |  \n",
      "     |  on_msg(self, callback, remove=False)\n",
      "     |      (Un)Register a custom msg receive callback.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      callback: callable\n",
      "     |          callback will be passed three arguments when a message arrives::\n",
      "     |      \n",
      "     |              callback(widget, content, buffers)\n",
      "     |      \n",
      "     |      remove: bool\n",
      "     |          True if the callback should be unregistered.\n",
      "     |  \n",
      "     |  open(self)\n",
      "     |      Open a comm to the frontend if one isn't already open.\n",
      "     |  \n",
      "     |  send(self, content, buffers=None)\n",
      "     |      Sends a custom msg to the widget model in the front-end.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      content : dict\n",
      "     |          Content of the message to send.\n",
      "     |      buffers : list of binary buffers\n",
      "     |          Binary buffers to send with message\n",
      "     |  \n",
      "     |  send_state(self, key=None)\n",
      "     |      Sends the widget state, or a piece of it, to the front-end, if it exists.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      key : unicode, or iterable (optional)\n",
      "     |          A single property's name or iterable of property names to sync with the front-end.\n",
      "     |  \n",
      "     |  set_state(self, sync_data)\n",
      "     |      Called when a state is received from the front-end.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from ipywidgets.widgets.widget.Widget:\n",
      "     |  \n",
      "     |  get_manager_state(drop_defaults=False, widgets=None)\n",
      "     |      Returns the full state for a widget manager for embedding\n",
      "     |      \n",
      "     |      :param drop_defaults: when True, it will not include default value\n",
      "     |      :param widgets: list with widgets to include in the state (or all widgets when None)\n",
      "     |      :return:\n",
      "     |  \n",
      "     |  handle_comm_opened(comm, msg)\n",
      "     |      Static method, called when a widget is constructed.\n",
      "     |  \n",
      "     |  on_widget_constructed(callback)\n",
      "     |      Registers a callback to be called when a widget is constructed.\n",
      "     |      \n",
      "     |      The callback must have the following signature:\n",
      "     |      callback(widget)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from ipywidgets.widgets.widget.Widget:\n",
      "     |  \n",
      "     |  comm\n",
      "     |      A trait whose value must be an instance of a specified class.\n",
      "     |      \n",
      "     |      The value can also be an instance of a subclass of the specified class.\n",
      "     |      \n",
      "     |      Subclasses can declare default classes by overriding the klass attribute\n",
      "     |  \n",
      "     |  keys\n",
      "     |      An instance of a Python list.\n",
      "     |  \n",
      "     |  model_id\n",
      "     |      Gets the model id of this widget.\n",
      "     |      \n",
      "     |      If a Comm doesn't exist yet, a Comm will be created automagically.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from ipywidgets.widgets.widget.Widget:\n",
      "     |  \n",
      "     |  widget_types = <ipywidgets.widgets.widget.WidgetRegistry object>\n",
      "     |  \n",
      "     |  widgets = {}\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from ipywidgets.widgets.widget.LoggingHasTraits:\n",
      "     |  \n",
      "     |  log\n",
      "     |      A trait whose value must be an instance of a specified class.\n",
      "     |      \n",
      "     |      The value can also be an instance of a subclass of the specified class.\n",
      "     |      \n",
      "     |      Subclasses can declare default classes by overriding the klass attribute\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from traitlets.traitlets.HasTraits:\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |  \n",
      "     |  has_trait(self, name)\n",
      "     |      Returns True if the object has a trait with the specified name.\n",
      "     |  \n",
      "     |  hold_trait_notifications(self)\n",
      "     |      Context manager for bundling trait change notifications and cross\n",
      "     |      validation.\n",
      "     |      \n",
      "     |      Use this when doing multiple trait assignments (init, config), to avoid\n",
      "     |      race conditions in trait notifiers requesting other trait values.\n",
      "     |      All trait notifications will fire after all values have been assigned.\n",
      "     |  \n",
      "     |  observe(self, handler, names=traitlets.All, type='change')\n",
      "     |      Setup a handler to be called when a trait changes.\n",
      "     |      \n",
      "     |      This is used to setup dynamic notifications of trait changes.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      handler : callable\n",
      "     |          A callable that is called when a trait changes. Its\n",
      "     |          signature should be ``handler(change)``, where ``change`` is a\n",
      "     |          dictionary. The change dictionary at least holds a 'type' key.\n",
      "     |          * ``type``: the type of notification.\n",
      "     |          Other keys may be passed depending on the value of 'type'. In the\n",
      "     |          case where type is 'change', we also have the following keys:\n",
      "     |          * ``owner`` : the HasTraits instance\n",
      "     |          * ``old`` : the old value of the modified trait attribute\n",
      "     |          * ``new`` : the new value of the modified trait attribute\n",
      "     |          * ``name`` : the name of the modified trait attribute.\n",
      "     |      names : list, str, All\n",
      "     |          If names is All, the handler will apply to all traits.  If a list\n",
      "     |          of str, handler will apply to all names in the list.  If a\n",
      "     |          str, the handler will apply just to that name.\n",
      "     |      type : str, All (default: 'change')\n",
      "     |          The type of notification to filter by. If equal to All, then all\n",
      "     |          notifications are passed to the observe handler.\n",
      "     |  \n",
      "     |  on_trait_change(self, handler=None, name=None, remove=False)\n",
      "     |      DEPRECATED: Setup a handler to be called when a trait changes.\n",
      "     |      \n",
      "     |      This is used to setup dynamic notifications of trait changes.\n",
      "     |      \n",
      "     |      Static handlers can be created by creating methods on a HasTraits\n",
      "     |      subclass with the naming convention '_[traitname]_changed'.  Thus,\n",
      "     |      to create static handler for the trait 'a', create the method\n",
      "     |      _a_changed(self, name, old, new) (fewer arguments can be used, see\n",
      "     |      below).\n",
      "     |      \n",
      "     |      If `remove` is True and `handler` is not specified, all change\n",
      "     |      handlers for the specified name are uninstalled.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      handler : callable, None\n",
      "     |          A callable that is called when a trait changes.  Its\n",
      "     |          signature can be handler(), handler(name), handler(name, new),\n",
      "     |          handler(name, old, new), or handler(name, old, new, self).\n",
      "     |      name : list, str, None\n",
      "     |          If None, the handler will apply to all traits.  If a list\n",
      "     |          of str, handler will apply to all names in the list.  If a\n",
      "     |          str, the handler will apply just to that name.\n",
      "     |      remove : bool\n",
      "     |          If False (the default), then install the handler.  If True\n",
      "     |          then unintall it.\n",
      "     |  \n",
      "     |  set_trait(self, name, value)\n",
      "     |      Forcibly sets trait attribute, including read-only attributes.\n",
      "     |  \n",
      "     |  setup_instance(self, *args, **kwargs)\n",
      "     |      This is called **before** self.__init__ is called.\n",
      "     |  \n",
      "     |  trait_metadata(self, traitname, key, default=None)\n",
      "     |      Get metadata values for trait by key.\n",
      "     |  \n",
      "     |  trait_names(self, **metadata)\n",
      "     |      Get a list of all the names of this class' traits.\n",
      "     |  \n",
      "     |  traits(self, **metadata)\n",
      "     |      Get a ``dict`` of all the traits of this class.  The dictionary\n",
      "     |      is keyed on the name and the values are the TraitType objects.\n",
      "     |      \n",
      "     |      The TraitTypes returned don't know anything about the values\n",
      "     |      that the various HasTrait's instances are holding.\n",
      "     |      \n",
      "     |      The metadata kwargs allow functions to be passed in which\n",
      "     |      filter traits based on metadata values.  The functions should\n",
      "     |      take a single value as an argument and return a boolean.  If\n",
      "     |      any function returns False, then the trait is not included in\n",
      "     |      the output.  If a metadata key doesn't exist, None will be passed\n",
      "     |      to the function.\n",
      "     |  \n",
      "     |  unobserve(self, handler, names=traitlets.All, type='change')\n",
      "     |      Remove a trait change handler.\n",
      "     |      \n",
      "     |      This is used to unregister handlers to trait change notifications.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      handler : callable\n",
      "     |          The callable called when a trait attribute changes.\n",
      "     |      names : list, str, All (default: All)\n",
      "     |          The names of the traits for which the specified handler should be\n",
      "     |          uninstalled. If names is All, the specified handler is uninstalled\n",
      "     |          from the list of notifiers corresponding to all changes.\n",
      "     |      type : str or All (default: 'change')\n",
      "     |          The type of notification to filter by. If All, the specified handler\n",
      "     |          is uninstalled from the list of notifiers corresponding to all types.\n",
      "     |  \n",
      "     |  unobserve_all(self, name=traitlets.All)\n",
      "     |      Remove trait change handlers of any type for the specified name.\n",
      "     |      If name is not specified, removes all trait notifiers.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from traitlets.traitlets.HasTraits:\n",
      "     |  \n",
      "     |  class_own_trait_events(name) from traitlets.traitlets.MetaHasTraits\n",
      "     |      Get a dict of all event handlers defined on this class, not a parent.\n",
      "     |      \n",
      "     |      Works like ``event_handlers``, except for excluding traits from parents.\n",
      "     |  \n",
      "     |  class_own_traits(**metadata) from traitlets.traitlets.MetaHasTraits\n",
      "     |      Get a dict of all the traitlets defined on this class, not a parent.\n",
      "     |      \n",
      "     |      Works like `class_traits`, except for excluding traits from parents.\n",
      "     |  \n",
      "     |  class_trait_names(**metadata) from traitlets.traitlets.MetaHasTraits\n",
      "     |      Get a list of all the names of this class' traits.\n",
      "     |      \n",
      "     |      This method is just like the :meth:`trait_names` method,\n",
      "     |      but is unbound.\n",
      "     |  \n",
      "     |  class_traits(**metadata) from traitlets.traitlets.MetaHasTraits\n",
      "     |      Get a ``dict`` of all the traits of this class.  The dictionary\n",
      "     |      is keyed on the name and the values are the TraitType objects.\n",
      "     |      \n",
      "     |      This method is just like the :meth:`traits` method, but is unbound.\n",
      "     |      \n",
      "     |      The TraitTypes returned don't know anything about the values\n",
      "     |      that the various HasTrait's instances are holding.\n",
      "     |      \n",
      "     |      The metadata kwargs allow functions to be passed in which\n",
      "     |      filter traits based on metadata values.  The functions should\n",
      "     |      take a single value as an argument and return a boolean.  If\n",
      "     |      any function returns False, then the trait is not included in\n",
      "     |      the output.  If a metadata key doesn't exist, None will be passed\n",
      "     |      to the function.\n",
      "     |  \n",
      "     |  trait_events(name=None) from traitlets.traitlets.MetaHasTraits\n",
      "     |      Get a ``dict`` of all the event handlers of this class.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      name: str (default: None)\n",
      "     |          The name of a trait of this class. If name is ``None`` then all\n",
      "     |          the event handlers of this class will be returned instead.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      The event handlers associated with a trait name, or all event handlers.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from traitlets.traitlets.HasTraits:\n",
      "     |  \n",
      "     |  cross_validation_lock\n",
      "     |      A contextmanager for running a block with our cross validation lock set\n",
      "     |      to True.\n",
      "     |      \n",
      "     |      At the end of the block, the lock's value is restored to its value\n",
      "     |      prior to entering the block.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from traitlets.traitlets.HasDescriptors:\n",
      "     |  \n",
      "     |  __new__(cls, *args, **kwargs)\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from traitlets.traitlets.HasDescriptors:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class Pool(_catboost._PoolBase)\n",
      "     |  Pool used in CatBoost as data structure to train model from.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Pool\n",
      "     |      _catboost._PoolBase\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, data, label=None, cat_features=None, column_description=None, pairs=None, delimiter='\\t', has_header=False, weight=None, group_id=None, subgroup_id=None, pairs_weight=None, baseline=None, feature_names=None, thread_count=-1)\n",
      "     |      Pool is a internal data structure that used by CatBoost.\n",
      "     |      You can construct Pool from list, numpy.array, pandas.DataFrame, pandas.Series.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      data : list or numpy.array or pandas.DataFrame or pandas.Series or string\n",
      "     |          Data source of Pool.\n",
      "     |          If list or numpy.arrays or pandas.DataFrame or pandas.Series, giving 2 dimensional array like data.\n",
      "     |          If string, giving the path to the file with data in catboost format.\n",
      "     |      \n",
      "     |      label : list or numpy.arrays or pandas.DataFrame or pandas.Series, optional (default=None)\n",
      "     |          Label of the training data.\n",
      "     |          If not  None, giving 1 dimensional array like data with floats.\n",
      "     |      \n",
      "     |      cat_features : list or numpy.array, optional (default=None)\n",
      "     |          If not None, giving the list of Categ columns indices.\n",
      "     |      \n",
      "     |      column_description : string, optional (default=None)\n",
      "     |          ColumnsDescription parameter.\n",
      "     |          There are several columns description types: Label, Categ, Num, Auxiliary, DocId, Weight, Baseline, GroupId, Timestamp.\n",
      "     |          All columns are Num as default, it's not necessary to specify\n",
      "     |          this type of columns. Default Label column index is 0 (zero).\n",
      "     |          If None, Label column is 0 (zero) as default, all data columns are Num as default.\n",
      "     |          If string, giving the path to the file with ColumnsDescription in column_description format.\n",
      "     |      \n",
      "     |      pairs : list or numpy.array or pandas.DataFrame or string\n",
      "     |          The pairs description.\n",
      "     |          If list or numpy.arrays or pandas.DataFrame, giving 2 dimensional.\n",
      "     |          The shape should be Nx2, where N is the pairs' count. The first element of pair is\n",
      "     |          the index of winner object in training set. The second element of pair is\n",
      "     |          the index of loser object in training set.\n",
      "     |          If string, giving the path to the file with pairs description.\n",
      "     |      \n",
      "     |      delimiter : string, optional (default=' ')\n",
      "     |          Delimiter to use for separate features in file.\n",
      "     |          Should be only one symbol, otherwise would be taken only the first character of the string.\n",
      "     |      \n",
      "     |      has_header : boolm optional (default=False)\n",
      "     |          If True, read column names from first line.\n",
      "     |      \n",
      "     |      weight : list or numpy.array, optional (default=None)\n",
      "     |          Weight for each instance.\n",
      "     |          If not None, giving 1 dimensional array like data.\n",
      "     |      \n",
      "     |      group_id : list or numpy.array, optional (default=None)\n",
      "     |          group id for each instance.\n",
      "     |          If not None, giving 1 dimensional array like data.\n",
      "     |      \n",
      "     |      subgroup_id : list or numpy.array, optional (default=None)\n",
      "     |          subgroup id for each instance.\n",
      "     |          If not None, giving 1 dimensional array like data.\n",
      "     |      \n",
      "     |      pairs_weight : list or numpy.array, optional (default=None)\n",
      "     |          Weight for each pair.\n",
      "     |          If not None, giving 1 dimensional array like pairs.\n",
      "     |      \n",
      "     |      baseline : list or numpy.array, optional (default=None)\n",
      "     |          Baseline for each instance.\n",
      "     |          If not None, giving 2 dimensional array like data.\n",
      "     |      \n",
      "     |      feature_names : list, optional (default=None)\n",
      "     |          Names for each given data_feature.\n",
      "     |      \n",
      "     |      thread_count : int, optional (default=-1)\n",
      "     |          Thread count to read data from file.\n",
      "     |          Use only with reading data from file.\n",
      "     |          If -1, then the number of threads is set to the number of cores.\n",
      "     |  \n",
      "     |  set_baseline(self, baseline)\n",
      "     |  \n",
      "     |  set_feature_names(self, feature_names)\n",
      "     |  \n",
      "     |  set_group_id(self, group_id)\n",
      "     |  \n",
      "     |  set_pairs(self, pairs)\n",
      "     |  \n",
      "     |  set_pairs_weight(self, pairs_weight)\n",
      "     |  \n",
      "     |  set_subgroup_id(self, subgroup_id)\n",
      "     |  \n",
      "     |  set_weight(self, weight)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from _catboost._PoolBase:\n",
      "     |  \n",
      "     |  __deepcopy__(...)\n",
      "     |  \n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  __reduce__ = __reduce_cython__(...)\n",
      "     |  \n",
      "     |  __setstate__ = __setstate_cython__(...)\n",
      "     |  \n",
      "     |  get_baseline(...)\n",
      "     |      Get baseline from Pool.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      baseline : list(list)\n",
      "     |  \n",
      "     |  get_cat_feature_hash_to_string(...)\n",
      "     |      Get maping of float hash values to corresponding strings\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      hash_to_string : map\n",
      "     |  \n",
      "     |  get_cat_feature_indices(...)\n",
      "     |      Get cat_feature indices from Pool.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      cat_feature_indices : list\n",
      "     |  \n",
      "     |  get_feature_names(...)\n",
      "     |  \n",
      "     |  get_features(...)\n",
      "     |      Get feature matrix from Pool.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      feature matrix : list(list)\n",
      "     |  \n",
      "     |  get_label(...)\n",
      "     |      Get labels from Pool.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      labels : list\n",
      "     |  \n",
      "     |  get_weight(...)\n",
      "     |      Get weight for each instance.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      weight : list\n",
      "     |  \n",
      "     |  num_col(...)\n",
      "     |      Get the number of columns in the Pool.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      number of cols : int\n",
      "     |  \n",
      "     |  num_pairs(...)\n",
      "     |      Get the number of pairs in the Pool.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      number of pairs : int\n",
      "     |  \n",
      "     |  num_row(...)\n",
      "     |      Get the number of rows in the Pool.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      number of rows : int\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from _catboost._PoolBase:\n",
      "     |  \n",
      "     |  is_empty_\n",
      "     |      Check if Pool is empty.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      is_empty_ : bool\n",
      "     |  \n",
      "     |  shape\n",
      "     |      Get the shape of the Pool.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      shape : (int, int)\n",
      "     |          (rows, cols)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from _catboost._PoolBase:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __pyx_vtable__ = <capsule object NULL>\n",
      "\n",
      "FUNCTIONS\n",
      "    cv(pool=None, params=None, dtrain=None, iterations=None, num_boost_round=None, fold_count=3, nfold=None, inverted=False, partition_random_seed=0, seed=None, shuffle=True, logging_level=None, stratified=False, as_pandas=True, verbose=None, verbose_eval=None, plot=False)\n",
      "        Cross-validate the CatBoost model.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        pool : catboost.Pool\n",
      "            Data to cross-validatte.\n",
      "        \n",
      "        params : dict\n",
      "            Parameters for CatBoost.\n",
      "            CatBoost has many of parameters, all have default values.\n",
      "            If  None, all params still defaults.\n",
      "            If  dict, overriding some (or all) params.\n",
      "        \n",
      "        dtrain : catboost.Pool or tuple (X, y)\n",
      "            Synonym for pool parameter. Only one of these parameters should be set.\n",
      "        \n",
      "        iterations : int\n",
      "            Number of boosting iterations. Can be set in params dict.\n",
      "        \n",
      "        num_boost_round : int\n",
      "            Synonym for iterations. Only one of these parameters should be set.\n",
      "        \n",
      "        fold_count : int, optional (default=3)\n",
      "            The number of folds to split the dataset into.\n",
      "        \n",
      "        nfold : int\n",
      "            Synonym for fold_count.\n",
      "        \n",
      "        inverted : bool, optional (default=False)\n",
      "            Train on the test fold and evaluate the model on the training folds.\n",
      "        \n",
      "        partition_random_seed : int, optional (default=0)\n",
      "            Use this as the seed value for random permutation of the data.\n",
      "            Permutation is performed before splitting the data for cross validation.\n",
      "            Each seed generates unique data splits.\n",
      "        \n",
      "        seed : int, optional\n",
      "            Synonym for partition_random_seed. This parameter is deprecated. Use\n",
      "            partition_random_seed instead.\n",
      "            If both parameters are initialised partition_random_seed parameter is\n",
      "            ignored.\n",
      "        \n",
      "        shuffle : bool, optional (default=True)\n",
      "            Shuffle the dataset objects before splitting into folds.\n",
      "        \n",
      "        logging_level : string, optional (default=None)\n",
      "            Possible values:\n",
      "                - 'Silent'\n",
      "                - 'Verbose'\n",
      "                - 'Info'\n",
      "                - 'Debug'\n",
      "        \n",
      "        stratified : bool, optional (default=False)\n",
      "            Perform stratified sampling.\n",
      "        \n",
      "        as_pandas : bool, optional (default=True)\n",
      "            Return pd.DataFrame when pandas is installed.\n",
      "            If False or pandas is not installed, return dict.\n",
      "        \n",
      "        verbose : bool or int\n",
      "            If verbose is bool, then if set to True, logging_level is set to Verbose,\n",
      "            if set to False, logging_level is set to Silent.\n",
      "            If verbose is int, metric_period is set to verbose value and\n",
      "            logging_level is set to Verbose.\n",
      "        \n",
      "        verbose_eval : bool or int\n",
      "            Synonym for verbose. Only one of these parameters should be set.\n",
      "        \n",
      "        plot : bool, optional (default=False)\n",
      "            If True, drow train and eval error in Jupyter notebook\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        cv results : pandas.core.frame.DataFrame with cross-validation results\n",
      "            columns are: test-error-mean  test-error-std  train-error-mean  train-error-std\n",
      "    \n",
      "    train(pool=None, params=None, dtrain=None, logging_level=None, verbose=None, iterations=None, num_boost_round=None, evals=None, eval_set=None, plot=None, verbose_eval=None)\n",
      "        Train CatBoost model.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        params : dict\n",
      "            Parameters for CatBoost.\n",
      "            If  None, all params are set to their defaults.\n",
      "            If  dict, overriding parameters present in the dict.\n",
      "        \n",
      "        pool : catboost.Pool or tuple (X, y)\n",
      "            Data to train on.\n",
      "        \n",
      "        iterations : int\n",
      "            Number of boosting iterations. Can be set in params dict.\n",
      "        \n",
      "        evals : catboost.Pool or tuple (X, y)\n",
      "            Synonym for eval_set. Only one of these parameters should be set.\n",
      "        \n",
      "        verbose : bool\n",
      "            If set to True, then logging_level is set to Verbose, otherwise\n",
      "            logging_level is set to Silent.\n",
      "        \n",
      "        dtrain : catboost.Pool or tuple (X, y)\n",
      "            Synonym for pool parameter. Only one of these parameters should be set.\n",
      "        \n",
      "        logging_level : string, optional (default=None)\n",
      "            Possible values:\n",
      "                - 'Silent'\n",
      "                - 'Verbose'\n",
      "                - 'Info'\n",
      "                - 'Debug'\n",
      "        \n",
      "        verbose : bool or int\n",
      "            If verbose is bool, then if set to True, logging_level is set to Verbose,\n",
      "            if set to False, logging_level is set to Silent.\n",
      "            If verbose is int, metric_period is set to verbose value and\n",
      "            logging_level is set to Verbose.\n",
      "        \n",
      "        verbose_eval : bool or int\n",
      "            Synonym for verbose. Only one of these parameters should be set.\n",
      "        \n",
      "        iterations : int\n",
      "            Number of boosting iterations. Can be set in params dict.\n",
      "        \n",
      "        num_boost_round : int\n",
      "            Synonym for iterations. Only one of these parameters should be set.\n",
      "        \n",
      "        eval_set : catboost.Pool or tuple (X, y) or list [(X, y)]\n",
      "            Dataset for evaluation.\n",
      "        \n",
      "        plot : bool, optional (default=False)\n",
      "            If True, drow train and eval error in Jupyter notebook\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        model : CatBoost class\n",
      "\n",
      "DATA\n",
      "    __all__ = ['Pool', 'CatBoost', 'CatBoostClassifier', 'CatBoostRegresso...\n",
      "\n",
      "VERSION\n",
      "    0.8.1\n",
      "\n",
      "FILE\n",
      "    /home/aditya/.conda/envs/py3k/lib/python3.6/site-packages/catboost/__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
